{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determing the Best Loss Optimizer\n",
    "Comparing SGD vs Adam Optimizer\n",
    "\n",
    "### Model\n",
    "- model = GRU\n",
    "- batch_size = 32\n",
    "- epochs = 100\n",
    "- loss = mse\n",
    "\n",
    "\n",
    "### Data\n",
    "- time frame: 6 months | 6 months\n",
    "- features: all of them (110)\n",
    "- target: EDSS_6...EDSS_222\n",
    "- imputation \n",
    "    - target: interpolation (trailing ends for extrapolation)\n",
    "    - features: zero-imputation\n",
    "- time steps: exhaustive (37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matiasberretta/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import sklearn as sk\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import keras.layers as L\n",
    "import keras.models as M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns(col_list, n_months):\n",
    "    \n",
    "    \"\"\"takes in a list of column names and number of visits starting at 0\n",
    "    returns column list time-stepped and dovetailed\"\"\" \n",
    "    \n",
    "    return dovetail_names(*[time_step_names(i, n_months) for i in col_list])\n",
    "        \n",
    "def time_step_names(name, n_months):\n",
    "\n",
    "    return [(name + '_%d' % (j+1)) for j in range(-1,n_months*6, 6)]\n",
    "\n",
    "def dovetail_names(*kwargs):\n",
    "    zipped = zip(*kwargs)\n",
    "    l = []\n",
    "    for i in zipped:\n",
    "        for j in i:\n",
    "            l.append(j)\n",
    "    return l\n",
    "\n",
    "def stretch_input(Xtr, n_inputs, time_steps, pot):\n",
    "\n",
    "    \"\"\"Xtr_fill is empty 3D numpy array where we extend length of patient observation times t\n",
    "    pot stands for Patient Observation Time. We only need to do this for our X input\"\"\"\n",
    "    \n",
    "    Xtr_fill = np.zeros(shape=[Xtr.shape[0],time_steps,n_inputs*pot] , dtype = object) \n",
    "\n",
    "    for subject in range(Xtr.shape[0]):\n",
    "    \n",
    "        for i in range(time_steps):\n",
    "\n",
    "            temp = np.concatenate([Xtr[subject][i],Xtr[subject][i+1]]) # changed for pot = 3\n",
    "            Xtr_fill[subject][i] = temp\n",
    "            \n",
    "    return Xtr_fill\n",
    "\n",
    "def stack_times(data, name, n):\n",
    "    \n",
    "    \n",
    "    \"\"\"takes in dataframe, column name and n of time steps\n",
    "    and puts it in long format\"\"\"\n",
    "    \n",
    "    all_names = select_columns(name, n-1)\n",
    "    \n",
    "    l = []\n",
    "    \n",
    "    for col in all_names:\n",
    "        l.append(data[col].copy())\n",
    "    \n",
    "    stacked = l[0]\n",
    "    rest = l[1:]\n",
    "    \n",
    "    # stack Series and get dummy variables \n",
    "    stacked.append(rest)\n",
    "    \n",
    "    return stacked\n",
    "\n",
    "def stack_dummy(data, name, n):\n",
    "    \n",
    "    \n",
    "    \"\"\"takes in dataframe and column name\n",
    "    return that same feature split into dummy columns\n",
    "    across n time steps (adjacent)\"\"\"\n",
    "    \n",
    "    all_names = select_columns(name, n-1)\n",
    "    \n",
    "    l = []\n",
    "    \n",
    "    for col in all_names:\n",
    "        l.append(data[col].copy())\n",
    "    \n",
    "    f = l[0]\n",
    "    rest = l[1:]\n",
    "    \n",
    "    # stack Series and get dummy variables \n",
    "    pre_dummy = pd.get_dummies(f.append(rest))\n",
    "    \n",
    "    after_dummy = time_dummy(pre_dummy, n)\n",
    "    \n",
    "    dummy_value_names = generate_col_names(after_dummy, name)\n",
    "    time_stepped_dummy_names = time_step_dummy_value_names(dummy_value_names, n)\n",
    "    \n",
    "    for t in range(len(after_dummy)):\n",
    "        \n",
    "        after_dummy[t].columns = list(time_stepped_dummy_names[t])\n",
    "        \n",
    "    #untimed_names_to_order = column_names_per_time_step(col_names_together, \"what are you\", name[0])\n",
    "    #names_to_order = select_columns(untimed_names_to_order, n-1)\n",
    "\n",
    "    return pd.concat(after_dummy, axis = 1, sort = False), dummy_value_names\n",
    "\n",
    "\n",
    "def time_dummy(dummy_df, n):\n",
    "    \n",
    "    \"\"\"Separates long data frame into time steps \n",
    "    (508 subjects (rows) per time step)\"\"\"\n",
    "    \n",
    "    l = []\n",
    "    for i in range(n):\n",
    "        l.append(dummy_df.iloc[i*508:(i+1)*508,:].copy())\n",
    "    \n",
    "    return l\n",
    "\n",
    "def generate_col_names(after_dummy, name):\n",
    "    \n",
    "    \"\"\"Generates column names for result of pd.get_dummies on a feature\n",
    "    i.e. if A has values x and y, it will generate A_x, A_y\"\"\"\n",
    "    \n",
    "    return [(str(name[0]) + \"_\" + str(list(after_dummy[0].columns)[i])) for i in range(len(list(after_dummy[0].columns)))]\n",
    "\n",
    "def time_step_dummy_value_names(names, n_months):\n",
    "    \n",
    "    long_list = [(name + '_%d' % (j+1)) for j in range(-1,n_months*6, 6) for name in names]\n",
    "    return np.array(long_list).reshape(-1, len(names))\n",
    "\n",
    "def add_columns(add_to, name, names_per_t, n):\n",
    "    \n",
    "    n = n + 1\n",
    "    to_add, bare_names = stack_dummy(df, name, n)\n",
    "    to_remove = select_columns(name, n-1)\n",
    "    \n",
    "    \"\"\"add new dummied features to dataframes (copy)\n",
    "    and remove undummied version of features\n",
    "    name is a list\n",
    "    \n",
    "    encompasses stack_dummy\"\"\"\n",
    "    \n",
    "    newdf = add_to.copy()\n",
    "    column_names = list(to_add.columns)\n",
    "    \n",
    "    for i in range(len(column_names)):\n",
    "        newdf[column_names[i]] = to_add.iloc[:,i]\n",
    "    newdf.drop(to_remove,axis = 1, inplace = True)\n",
    "    \n",
    "    #print(bare_names, name[0])\n",
    "    \n",
    "    names_per_t_updated = column_names_per_time_step(names_per_t, bare_names, name[0])\n",
    "    namesOrder= select_columns(names_per_t_updated, n-1)\n",
    "    return newdf[namesOrder].copy(), names_per_t_updated\n",
    "\n",
    "#    return names_per_t_updated\n",
    "#     print(name[0])\n",
    "    \n",
    "    \n",
    "    return newdf[namesOrder].copy(), names_per_t_updated\n",
    "\n",
    "\n",
    "def column_names_per_time_step(original_list, add, remove):\n",
    "    \"\"\"makes sure EDSS stays at the end\n",
    "    remove pre \"\"\"\n",
    "    \n",
    "    new_list = original_list.copy()\n",
    "    \n",
    "    \n",
    "    new_list.remove(remove)\n",
    "    new_list.extend(add)\n",
    "    \n",
    "    # makes sure EDSS is always last\n",
    "    \n",
    "    new_list.remove('EDSS')\n",
    "    new_list.append('EDSS')\n",
    "    \n",
    "    return new_list\n",
    "\n",
    "def manual_dummy(df, names, name_list, n):\n",
    "    \n",
    "    dfUpdated =df.copy()\n",
    "    names = [[name] for name in names] # turn to list foramt so that it works\n",
    "    \n",
    "    for name in names:\n",
    "        \n",
    "        dfUpdated, name_list = add_columns(dfUpdated, name , name_list, n)\n",
    "   \n",
    "    return dfUpdated # should I return name_list as well?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATA & DEFINE N OF TIME STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RNN window will slide 37 times\n",
      "The input length of the training data will be 1 time slices, separated by 6 month intervals\n",
      "There will be 110 per time step\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv(\"../data/X_6_months|6_months_exhaustive.csv\", index_col = 0)\n",
    "y = pd.read_csv(\"../data/y_6_months|6_months_exhaustive.csv\", index_col = 0)\n",
    "\n",
    "predictive_features = pd.read_csv(\"../data/predictive_features_list.csv\", index_col = 0, header = None)\n",
    "predictive_features_list = predictive_features[1].values.tolist()\n",
    "\n",
    "n_time_steps = len(y.columns)\n",
    "n_inputs_pure = X.columns.tolist().index(\"EDSS_0\")+1\n",
    "\n",
    "pot = 1\n",
    "print(\"The RNN window will slide\", n_time_steps, \"times\")\n",
    "print(\"The input length of the training data will be\", pot, \"time slices, separated by 6 month intervals\")\n",
    "print(\"There will be\", n_inputs_pure, \"per time step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X reshaped is (355, 37, 110)\n",
      "y reshaped is (355, 37, 1)\n",
      "X reshaped is (153, 37, 110)\n",
      "y reshaped is (153, 37, 1)\n",
      "(355, 37, 110) (355, 37, 1) (153, 37, 110) (153, 37, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
    "\n",
    "# X train n_time_steps will be +1 to account for stretching\n",
    "# which will turn 11 time slices of 1 to 10 time slices of 2\n",
    "X_train_reshaped = X_train.values.reshape(-1, n_time_steps, n_inputs_pure) # extra time step for stretch\n",
    "y_train_reshaped = y_train.values.reshape(-1, n_time_steps, 1)\n",
    "print(\"X reshaped is \" + str(X_train_reshaped.shape))\n",
    "print(\"y reshaped is \" + str(y_train_reshaped.shape))\n",
    "\n",
    "X_test_reshaped = X_test.values.reshape(-1, n_time_steps, n_inputs_pure)\n",
    "y_test_reshaped = y_test.values.reshape(-1, n_time_steps, 1)\n",
    "print(\"X reshaped is \" + str(X_test_reshaped.shape))\n",
    "print(\"y reshaped is \" + str(y_test_reshaped.shape))\n",
    "\n",
    "y_train = y_train_reshaped.astype(float)\n",
    "y_test = y_test_reshaped.astype(float)\n",
    "X_train = X_train_reshaped.astype(float)\n",
    "X_test = X_test_reshaped.astype(float)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set values for the neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 inputs per time step ( 37 ) comprising 1 time slice, 110 features each\n"
     ]
    }
   ],
   "source": [
    "n_inputs = n_inputs_pure * pot\n",
    "\n",
    "n_units = 15\n",
    "\n",
    "n_output = 1\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "print(n_inputs, \"inputs per time step (\",n_time_steps,\") comprising\", pot, \"time slice,\", n_inputs_pure, \"features each\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 355 samples, validate on 153 samples\n",
      "Epoch 1/100\n",
      "355/355 [==============================] - 2s 6ms/step - loss: 5.5521 - val_loss: 4.7501\n",
      "Epoch 2/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 3.1616 - val_loss: 3.3742\n",
      "Epoch 3/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 2.0460 - val_loss: 2.3720\n",
      "Epoch 4/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 1.2633 - val_loss: 1.4432\n",
      "Epoch 5/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.7603 - val_loss: 0.9699\n",
      "Epoch 6/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.5669 - val_loss: 0.7851\n",
      "Epoch 7/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.4869 - val_loss: 0.7058\n",
      "Epoch 8/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.4226 - val_loss: 0.5968\n",
      "Epoch 9/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3900 - val_loss: 0.5678\n",
      "Epoch 10/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3684 - val_loss: 0.5242\n",
      "Epoch 11/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3516 - val_loss: 0.5120\n",
      "Epoch 12/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3456 - val_loss: 0.4963\n",
      "Epoch 13/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3362 - val_loss: 0.4599\n",
      "Epoch 14/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3222 - val_loss: 0.4469\n",
      "Epoch 15/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3156 - val_loss: 0.4380\n",
      "Epoch 16/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3091 - val_loss: 0.4329\n",
      "Epoch 17/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3040 - val_loss: 0.4293\n",
      "Epoch 18/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3030 - val_loss: 0.4227\n",
      "Epoch 19/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2972 - val_loss: 0.4170\n",
      "Epoch 20/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2920 - val_loss: 0.4109\n",
      "Epoch 21/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2887 - val_loss: 0.4127\n",
      "Epoch 22/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2859 - val_loss: 0.4040\n",
      "Epoch 23/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2831 - val_loss: 0.4009\n",
      "Epoch 24/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2811 - val_loss: 0.3954\n",
      "Epoch 25/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2775 - val_loss: 0.3946\n",
      "Epoch 26/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2758 - val_loss: 0.3927\n",
      "Epoch 27/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2733 - val_loss: 0.3888\n",
      "Epoch 28/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2707 - val_loss: 0.3826\n",
      "Epoch 29/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2692 - val_loss: 0.3776\n",
      "Epoch 30/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2664 - val_loss: 0.3769\n",
      "Epoch 31/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2653 - val_loss: 0.3757\n",
      "Epoch 32/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2650 - val_loss: 0.3773\n",
      "Epoch 33/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2625 - val_loss: 0.3723\n",
      "Epoch 34/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2604 - val_loss: 0.3668\n",
      "Epoch 35/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2595 - val_loss: 0.3647\n",
      "Epoch 36/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2599 - val_loss: 0.3799\n",
      "Epoch 37/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2569 - val_loss: 0.3789\n",
      "Epoch 38/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2550 - val_loss: 0.3772\n",
      "Epoch 39/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2549 - val_loss: 0.3728\n",
      "Epoch 40/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2519 - val_loss: 0.3726\n",
      "Epoch 41/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2510 - val_loss: 0.3686\n",
      "Epoch 42/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2488 - val_loss: 0.3697\n",
      "Epoch 43/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2485 - val_loss: 0.3640\n",
      "Epoch 44/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2466 - val_loss: 0.3610\n",
      "Epoch 45/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2460 - val_loss: 0.3558\n",
      "Epoch 46/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2442 - val_loss: 0.3452\n",
      "Epoch 47/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2426 - val_loss: 0.3380\n",
      "Epoch 48/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2424 - val_loss: 0.3384\n",
      "Epoch 49/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2408 - val_loss: 0.3377\n",
      "Epoch 50/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2398 - val_loss: 0.3467\n",
      "Epoch 51/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2398 - val_loss: 0.3373\n",
      "Epoch 52/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2384 - val_loss: 0.3383\n",
      "Epoch 53/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2375 - val_loss: 0.3390\n",
      "Epoch 54/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2357 - val_loss: 0.3441\n",
      "Epoch 55/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2348 - val_loss: 0.3400\n",
      "Epoch 56/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2356 - val_loss: 0.3313\n",
      "Epoch 57/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2328 - val_loss: 0.3400\n",
      "Epoch 58/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2331 - val_loss: 0.3356\n",
      "Epoch 59/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2307 - val_loss: 0.3400\n",
      "Epoch 60/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2303 - val_loss: 0.3307\n",
      "Epoch 61/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2298 - val_loss: 0.3404\n",
      "Epoch 62/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2326 - val_loss: 0.3446\n",
      "Epoch 63/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2295 - val_loss: 0.3373\n",
      "Epoch 64/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2277 - val_loss: 0.3352\n",
      "Epoch 65/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2264 - val_loss: 0.3343\n",
      "Epoch 66/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2256 - val_loss: 0.3320\n",
      "Epoch 67/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2243 - val_loss: 0.3381\n",
      "Epoch 68/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2239 - val_loss: 0.3330\n",
      "Epoch 69/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2227 - val_loss: 0.3315\n",
      "Epoch 70/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2222 - val_loss: 0.3323\n",
      "Epoch 71/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2201 - val_loss: 0.3349\n",
      "Epoch 72/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2202 - val_loss: 0.3382\n",
      "Epoch 73/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2208 - val_loss: 0.3410\n",
      "Epoch 74/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2195 - val_loss: 0.3291\n",
      "Epoch 75/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2186 - val_loss: 0.3412\n",
      "Epoch 76/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2176 - val_loss: 0.3308\n",
      "Epoch 77/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2181 - val_loss: 0.3352\n",
      "Epoch 78/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2166 - val_loss: 0.3325\n",
      "Epoch 79/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2146 - val_loss: 0.3281\n",
      "Epoch 80/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2140 - val_loss: 0.3286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2126 - val_loss: 0.3284\n",
      "Epoch 82/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2126 - val_loss: 0.3325\n",
      "Epoch 83/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2113 - val_loss: 0.3231\n",
      "Epoch 84/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2109 - val_loss: 0.3327\n",
      "Epoch 85/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2092 - val_loss: 0.3229\n",
      "Epoch 86/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2105 - val_loss: 0.3183\n",
      "Epoch 87/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2140 - val_loss: 0.3350\n",
      "Epoch 88/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2113 - val_loss: 0.3213\n",
      "Epoch 89/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2080 - val_loss: 0.3524\n",
      "Epoch 90/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2084 - val_loss: 0.3357\n",
      "Epoch 91/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2060 - val_loss: 0.3370\n",
      "Epoch 92/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2051 - val_loss: 0.3318\n",
      "Epoch 93/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2049 - val_loss: 0.3370\n",
      "Epoch 94/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2053 - val_loss: 0.3298\n",
      "Epoch 95/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2056 - val_loss: 0.3382\n",
      "Epoch 96/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2029 - val_loss: 0.3298\n",
      "Epoch 97/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2044 - val_loss: 0.3318\n",
      "Epoch 98/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2009 - val_loss: 0.3317\n",
      "Epoch 99/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.1990 - val_loss: 0.3274\n",
      "Epoch 100/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.1987 - val_loss: 0.3279\n"
     ]
    }
   ],
   "source": [
    "model_adam = M.Sequential()\n",
    "\n",
    "# Each input data point has 20 timesteps, each with 26 features.\n",
    "# So the input shape (excluding batch_size) is (20, 26), which\n",
    "# matches the shape of each data point in data_x above.\n",
    "model_adam.add(L.GRU(64, input_shape=(n_time_steps, n_inputs), return_sequences=True))\n",
    "model_adam.add(L.Dense(n_output, activation='linear'))\n",
    "\n",
    "# You need to pick appropriate loss/optimizers for your problem.\n",
    "# I'm just using these to make the example compile.\n",
    "model_adam.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "history_adam = model_adam.fit(X_train, y_train, batch_size = 32, \n",
    "                              epochs=100, validation_data=(X_test, y_test), \n",
    "                              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 355 samples, validate on 153 samples\n",
      "Epoch 1/100\n",
      "355/355 [==============================] - 3s 7ms/step - loss: 4.1419 - val_loss: 1.9385\n",
      "Epoch 2/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 1.1230 - val_loss: 3.8270\n",
      "Epoch 3/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 1.1464 - val_loss: 0.6962\n",
      "Epoch 4/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.5379 - val_loss: 1.1945\n",
      "Epoch 5/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.6528 - val_loss: 1.4388\n",
      "Epoch 6/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.6196 - val_loss: 0.6277\n",
      "Epoch 7/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.4110 - val_loss: 0.5995\n",
      "Epoch 8/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.4511 - val_loss: 0.5277\n",
      "Epoch 9/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.4408 - val_loss: 0.4987\n",
      "Epoch 10/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3537 - val_loss: 0.7647\n",
      "Epoch 11/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3898 - val_loss: 0.6278\n",
      "Epoch 12/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.4084 - val_loss: 0.4689\n",
      "Epoch 13/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3334 - val_loss: 0.5169\n",
      "Epoch 14/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3696 - val_loss: 0.4974\n",
      "Epoch 15/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3413 - val_loss: 0.5548\n",
      "Epoch 16/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3585 - val_loss: 0.4597\n",
      "Epoch 17/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3267 - val_loss: 0.4681\n",
      "Epoch 18/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3550 - val_loss: 0.5309\n",
      "Epoch 19/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3497 - val_loss: 0.5487\n",
      "Epoch 20/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3310 - val_loss: 0.4383\n",
      "Epoch 21/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3425 - val_loss: 0.5577\n",
      "Epoch 22/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3518 - val_loss: 0.4352\n",
      "Epoch 23/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3103 - val_loss: 0.5001\n",
      "Epoch 24/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3324 - val_loss: 0.4369\n",
      "Epoch 25/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3184 - val_loss: 0.4312\n",
      "Epoch 26/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3155 - val_loss: 0.4241\n",
      "Epoch 27/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3079 - val_loss: 0.4486\n",
      "Epoch 28/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3055 - val_loss: 0.4219\n",
      "Epoch 29/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2976 - val_loss: 0.5747\n",
      "Epoch 30/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3162 - val_loss: 0.3958\n",
      "Epoch 31/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3127 - val_loss: 0.4271\n",
      "Epoch 32/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3110 - val_loss: 0.3978\n",
      "Epoch 33/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2971 - val_loss: 0.3914\n",
      "Epoch 34/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2928 - val_loss: 0.3849\n",
      "Epoch 35/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2988 - val_loss: 0.3911\n",
      "Epoch 36/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2932 - val_loss: 0.4107\n",
      "Epoch 37/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3667 - val_loss: 0.4196\n",
      "Epoch 38/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2972 - val_loss: 0.4030\n",
      "Epoch 39/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3248 - val_loss: 0.4008\n",
      "Epoch 40/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3139 - val_loss: 0.4080\n",
      "Epoch 41/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2878 - val_loss: 0.4074\n",
      "Epoch 42/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2938 - val_loss: 0.4226\n",
      "Epoch 43/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3197 - val_loss: 0.4542\n",
      "Epoch 44/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3221 - val_loss: 0.5458\n",
      "Epoch 45/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3281 - val_loss: 0.3971\n",
      "Epoch 46/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2880 - val_loss: 0.4043\n",
      "Epoch 47/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2898 - val_loss: 0.3945\n",
      "Epoch 48/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3283 - val_loss: 0.3861\n",
      "Epoch 49/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2900 - val_loss: 0.3962\n",
      "Epoch 50/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2836 - val_loss: 0.4440\n",
      "Epoch 51/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3160 - val_loss: 0.3822\n",
      "Epoch 52/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2895 - val_loss: 0.3853\n",
      "Epoch 53/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2851 - val_loss: 0.3863\n",
      "Epoch 54/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2958 - val_loss: 0.3649\n",
      "Epoch 55/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2829 - val_loss: 0.3665\n",
      "Epoch 56/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2819 - val_loss: 0.3673\n",
      "Epoch 57/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2820 - val_loss: 0.3635\n",
      "Epoch 58/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2810 - val_loss: 0.4240\n",
      "Epoch 59/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2889 - val_loss: 0.3749\n",
      "Epoch 60/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3091 - val_loss: 0.5047\n",
      "Epoch 61/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3461 - val_loss: 0.4838\n",
      "Epoch 62/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3369 - val_loss: 0.3957\n",
      "Epoch 63/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2925 - val_loss: 0.4529\n",
      "Epoch 64/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3210 - val_loss: 0.4417\n",
      "Epoch 65/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3087 - val_loss: 0.4137\n",
      "Epoch 66/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2965 - val_loss: 0.3960\n",
      "Epoch 67/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2825 - val_loss: 0.3842\n",
      "Epoch 68/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2861 - val_loss: 0.3839\n",
      "Epoch 69/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2810 - val_loss: 0.3766\n",
      "Epoch 70/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2832 - val_loss: 0.3762\n",
      "Epoch 71/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2995 - val_loss: 0.3897\n",
      "Epoch 72/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3164 - val_loss: 0.3802\n",
      "Epoch 73/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2965 - val_loss: 0.3740\n",
      "Epoch 74/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3001 - val_loss: 0.3778\n",
      "Epoch 75/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2764 - val_loss: 0.3740\n",
      "Epoch 76/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2960 - val_loss: 0.4345\n",
      "Epoch 77/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2832 - val_loss: 0.3773\n",
      "Epoch 78/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2827 - val_loss: 0.3705\n",
      "Epoch 79/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2749 - val_loss: 0.3667\n",
      "Epoch 80/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2794 - val_loss: 0.3655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2905 - val_loss: 0.3651\n",
      "Epoch 82/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2856 - val_loss: 0.3765\n",
      "Epoch 83/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2882 - val_loss: 0.3695\n",
      "Epoch 84/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2895 - val_loss: 0.3612\n",
      "Epoch 85/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2858 - val_loss: 0.3681\n",
      "Epoch 86/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2818 - val_loss: 0.3589\n",
      "Epoch 87/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2802 - val_loss: 0.4304\n",
      "Epoch 88/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2803 - val_loss: 0.3610\n",
      "Epoch 89/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2746 - val_loss: 0.3491\n",
      "Epoch 90/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2737 - val_loss: 0.3490\n",
      "Epoch 91/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2752 - val_loss: 0.3781\n",
      "Epoch 92/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2922 - val_loss: 0.4997\n",
      "Epoch 93/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3481 - val_loss: 0.3623\n",
      "Epoch 94/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2709 - val_loss: 0.3642\n",
      "Epoch 95/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2733 - val_loss: 0.3841\n",
      "Epoch 96/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2779 - val_loss: 0.3902\n",
      "Epoch 97/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2734 - val_loss: 0.3671\n",
      "Epoch 98/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2690 - val_loss: 0.3716\n",
      "Epoch 99/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2717 - val_loss: 0.3764\n",
      "Epoch 100/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2703 - val_loss: 0.3648\n"
     ]
    }
   ],
   "source": [
    "model_sgd = M.Sequential()\n",
    "\n",
    "\n",
    "model_sgd.add(L.GRU(64, input_shape=(n_time_steps, n_inputs), return_sequences=True))\n",
    "model_sgd.add(L.Dense(n_output, activation='linear'))\n",
    "\n",
    "model_sgd.compile(optimizer = 'sgd', loss = 'mean_squared_error')\n",
    "\n",
    "history_sgd = model_sgd.fit(X_train, y_train, batch_size = 32, \n",
    "                              epochs=100, validation_data=(X_test, y_test), \n",
    "                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_test_sgd = history_sgd.__dict__['history']['val_loss']\n",
    "mse_train_sgd = history_sgd.__dict__['history']['loss']\n",
    "sgd_params = history_sgd.__dict__['params']\n",
    "\n",
    "mse_test_adam = history_adam.__dict__['history']['val_loss']\n",
    "mse_train_adam = history_adam.__dict__['history']['loss']\n",
    "adam_params = history_adam.__dict__['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Train Scores\n",
      "SGD 0.2689943426931408\n",
      "SGD epoch: 97\n",
      "Adam 0.19873997564886658\n",
      "Adam epoch: 99\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mse_train_adam)\n",
    "plt.plot(mse_train_sgd)\n",
    "\n",
    "plt.legend(['train_adam','train_sgd'])\n",
    "\n",
    "print(\"Best Train Scores\")\n",
    "print(\"SGD\", np.min(mse_train_sgd))\n",
    "print(\"SGD epoch:\",np.argmin(mse_train_sgd))\n",
    "\n",
    "print(\"Adam\", np.min(mse_train_adam))\n",
    "print(\"Adam epoch:\",np.argmin(mse_train_adam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Test Scores\n",
      "SGD 0.3490061436603272\n",
      "SGD epoch: 89\n",
      "Adam 0.31834179357765546\n",
      "Adam epoch: 85\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mse_test_adam)\n",
    "plt.plot(mse_test_sgd)\n",
    "\n",
    "plt.legend(['test_adam','test_sgd'])\n",
    "\n",
    "print(\"Best Test Scores\")\n",
    "print(\"SGD\", np.min(mse_test_sgd))\n",
    "print(\"SGD epoch:\",np.argmin(mse_test_sgd))\n",
    "\n",
    "print(\"Adam\", np.min(mse_test_adam))\n",
    "print(\"Adam epoch:\",np.argmin(mse_test_adam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRU_df = pd.concat([pd.DataFrame(mse_test_adam, columns=['Adam Test MSE']),\n",
    "pd.DataFrame(mse_test_sgd, columns=['SGD Test MSE']),\n",
    "pd.DataFrame(mse_train_adam, columns=['Adam Train MSE']),\n",
    "pd.DataFrame(mse_train_sgd, columns=['SGD Train MSE'])], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRU_df.to_csv('GRU_df_parametrization.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
