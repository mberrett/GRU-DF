{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Optimizer\n",
    "Comparing SGD vs Adam Optimizer\n",
    "\n",
    "### Model\n",
    "- model = LSTM\n",
    "- batch_size = 32\n",
    "- epochs = 100\n",
    "- loss = mse\n",
    "\n",
    "\n",
    "### Data\n",
    "- time frame: 6 months | 6 months\n",
    "- features: all of them (110)\n",
    "- target: EDSS_6...EDSS_222\n",
    "- imputation \n",
    "    - target: interpolation (trailing ends for extrapolation)\n",
    "    - features: zero-imputation\n",
    "- time steps: exhaustive (37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matiasberretta/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import sklearn as sk\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import keras.layers as L\n",
    "import keras.models as M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns(col_list, n_months):\n",
    "    \n",
    "    \"\"\"takes in a list of column names and number of visits starting at 0\n",
    "    returns column list time-stepped and dovetailed\"\"\" \n",
    "    \n",
    "    return dovetail_names(*[time_step_names(i, n_months) for i in col_list])\n",
    "        \n",
    "def time_step_names(name, n_months):\n",
    "\n",
    "    return [(name + '_%d' % (j+1)) for j in range(-1,n_months*6, 6)]\n",
    "\n",
    "def dovetail_names(*kwargs):\n",
    "    zipped = zip(*kwargs)\n",
    "    l = []\n",
    "    for i in zipped:\n",
    "        for j in i:\n",
    "            l.append(j)\n",
    "    return l\n",
    "\n",
    "def stretch_input(Xtr, n_inputs, time_steps, pot):\n",
    "\n",
    "    \"\"\"Xtr_fill is empty 3D numpy array where we extend length of patient observation times t\n",
    "    pot stands for Patient Observation Time. We only need to do this for our X input\"\"\"\n",
    "    \n",
    "    Xtr_fill = np.zeros(shape=[Xtr.shape[0],time_steps,n_inputs*pot] , dtype = object) \n",
    "\n",
    "    for subject in range(Xtr.shape[0]):\n",
    "    \n",
    "        for i in range(time_steps):\n",
    "\n",
    "            temp = np.concatenate([Xtr[subject][i],Xtr[subject][i+1]]) # changed for pot = 3\n",
    "            Xtr_fill[subject][i] = temp\n",
    "            \n",
    "    return Xtr_fill\n",
    "\n",
    "def stack_times(data, name, n):\n",
    "    \n",
    "    \n",
    "    \"\"\"takes in dataframe, column name and n of time steps\n",
    "    and puts it in long format\"\"\"\n",
    "    \n",
    "    all_names = select_columns(name, n-1)\n",
    "    \n",
    "    l = []\n",
    "    \n",
    "    for col in all_names:\n",
    "        l.append(data[col].copy())\n",
    "    \n",
    "    stacked = l[0]\n",
    "    rest = l[1:]\n",
    "    \n",
    "    # stack Series and get dummy variables \n",
    "    stacked.append(rest)\n",
    "    \n",
    "    return stacked\n",
    "\n",
    "def stack_dummy(data, name, n):\n",
    "    \n",
    "    \n",
    "    \"\"\"takes in dataframe and column name\n",
    "    return that same feature split into dummy columns\n",
    "    across n time steps (adjacent)\"\"\"\n",
    "    \n",
    "    all_names = select_columns(name, n-1)\n",
    "    \n",
    "    l = []\n",
    "    \n",
    "    for col in all_names:\n",
    "        l.append(data[col].copy())\n",
    "    \n",
    "    f = l[0]\n",
    "    rest = l[1:]\n",
    "    \n",
    "    # stack Series and get dummy variables \n",
    "    pre_dummy = pd.get_dummies(f.append(rest))\n",
    "    \n",
    "    after_dummy = time_dummy(pre_dummy, n)\n",
    "    \n",
    "    dummy_value_names = generate_col_names(after_dummy, name)\n",
    "    time_stepped_dummy_names = time_step_dummy_value_names(dummy_value_names, n)\n",
    "    \n",
    "    for t in range(len(after_dummy)):\n",
    "        \n",
    "        after_dummy[t].columns = list(time_stepped_dummy_names[t])\n",
    "        \n",
    "    #untimed_names_to_order = column_names_per_time_step(col_names_together, \"what are you\", name[0])\n",
    "    #names_to_order = select_columns(untimed_names_to_order, n-1)\n",
    "\n",
    "    return pd.concat(after_dummy, axis = 1, sort = False), dummy_value_names\n",
    "\n",
    "\n",
    "def time_dummy(dummy_df, n):\n",
    "    \n",
    "    \"\"\"Separates long data frame into time steps \n",
    "    (508 subjects (rows) per time step)\"\"\"\n",
    "    \n",
    "    l = []\n",
    "    for i in range(n):\n",
    "        l.append(dummy_df.iloc[i*508:(i+1)*508,:].copy())\n",
    "    \n",
    "    return l\n",
    "\n",
    "def generate_col_names(after_dummy, name):\n",
    "    \n",
    "    \"\"\"Generates column names for result of pd.get_dummies on a feature\n",
    "    i.e. if A has values x and y, it will generate A_x, A_y\"\"\"\n",
    "    \n",
    "    return [(str(name[0]) + \"_\" + str(list(after_dummy[0].columns)[i])) for i in range(len(list(after_dummy[0].columns)))]\n",
    "\n",
    "def time_step_dummy_value_names(names, n_months):\n",
    "    \n",
    "    long_list = [(name + '_%d' % (j+1)) for j in range(-1,n_months*6, 6) for name in names]\n",
    "    return np.array(long_list).reshape(-1, len(names))\n",
    "\n",
    "def add_columns(add_to, name, names_per_t, n):\n",
    "    \n",
    "    n = n + 1\n",
    "    to_add, bare_names = stack_dummy(df, name, n)\n",
    "    to_remove = select_columns(name, n-1)\n",
    "    \n",
    "    \"\"\"add new dummied features to dataframes (copy)\n",
    "    and remove undummied version of features\n",
    "    name is a list\n",
    "    \n",
    "    encompasses stack_dummy\"\"\"\n",
    "    \n",
    "    newdf = add_to.copy()\n",
    "    column_names = list(to_add.columns)\n",
    "    \n",
    "    for i in range(len(column_names)):\n",
    "        newdf[column_names[i]] = to_add.iloc[:,i]\n",
    "    newdf.drop(to_remove,axis = 1, inplace = True)\n",
    "    \n",
    "    #print(bare_names, name[0])\n",
    "    \n",
    "    names_per_t_updated = column_names_per_time_step(names_per_t, bare_names, name[0])\n",
    "    namesOrder= select_columns(names_per_t_updated, n-1)\n",
    "    return newdf[namesOrder].copy(), names_per_t_updated\n",
    "\n",
    "#    return names_per_t_updated\n",
    "#     print(name[0])\n",
    "    \n",
    "    \n",
    "    return newdf[namesOrder].copy(), names_per_t_updated\n",
    "\n",
    "\n",
    "def column_names_per_time_step(original_list, add, remove):\n",
    "    \"\"\"makes sure EDSS stays at the end\n",
    "    remove pre \"\"\"\n",
    "    \n",
    "    new_list = original_list.copy()\n",
    "    \n",
    "    \n",
    "    new_list.remove(remove)\n",
    "    new_list.extend(add)\n",
    "    \n",
    "    # makes sure EDSS is always last\n",
    "    \n",
    "    new_list.remove('EDSS')\n",
    "    new_list.append('EDSS')\n",
    "    \n",
    "    return new_list\n",
    "\n",
    "def manual_dummy(df, names, name_list, n):\n",
    "    \n",
    "    dfUpdated =df.copy()\n",
    "    names = [[name] for name in names] # turn to list foramt so that it works\n",
    "    \n",
    "    for name in names:\n",
    "        \n",
    "        dfUpdated, name_list = add_columns(dfUpdated, name , name_list, n)\n",
    "   \n",
    "    return dfUpdated # should I return name_list as well?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATA & DEFINE N OF TIME STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RNN window will slide 37 times\n",
      "The input length of the training data will be 1 time slices, separated by 6 month intervals\n",
      "There will be 110 per time step\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv(\"../data/X_6_months|6_months_exhaustive.csv\", index_col = 0)\n",
    "y = pd.read_csv(\"../data/y_6_months|6_months_exhaustive.csv\", index_col = 0)\n",
    "\n",
    "predictive_features = pd.read_csv(\"../data/predictive_features_list.csv\", index_col = 0, header = None)\n",
    "predictive_features_list = predictive_features[1].values.tolist()\n",
    "\n",
    "n_time_steps = len(y.columns)\n",
    "n_inputs_pure = X.columns.tolist().index(\"EDSS_0\")+1\n",
    "\n",
    "pot = 1\n",
    "print(\"The RNN window will slide\", n_time_steps, \"times\")\n",
    "print(\"The input length of the training data will be\", pot, \"time slices, separated by 6 month intervals\")\n",
    "print(\"There will be\", n_inputs_pure, \"per time step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X reshaped is (355, 37, 110)\n",
      "y reshaped is (355, 37, 1)\n",
      "X reshaped is (153, 37, 110)\n",
      "y reshaped is (153, 37, 1)\n",
      "(355, 37, 110) (355, 37, 1) (153, 37, 110) (153, 37, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
    "\n",
    "# X train n_time_steps will be +1 to account for stretching\n",
    "# which will turn 11 time slices of 1 to 10 time slices of 2\n",
    "X_train_reshaped = X_train.values.reshape(-1, n_time_steps, n_inputs_pure) # extra time step for stretch\n",
    "y_train_reshaped = y_train.values.reshape(-1, n_time_steps, 1)\n",
    "print(\"X reshaped is \" + str(X_train_reshaped.shape))\n",
    "print(\"y reshaped is \" + str(y_train_reshaped.shape))\n",
    "\n",
    "X_test_reshaped = X_test.values.reshape(-1, n_time_steps, n_inputs_pure)\n",
    "y_test_reshaped = y_test.values.reshape(-1, n_time_steps, 1)\n",
    "print(\"X reshaped is \" + str(X_test_reshaped.shape))\n",
    "print(\"y reshaped is \" + str(y_test_reshaped.shape))\n",
    "\n",
    "y_train = y_train_reshaped.astype(float)\n",
    "y_test = y_test_reshaped.astype(float)\n",
    "X_train = X_train_reshaped.astype(float)\n",
    "X_test = X_test_reshaped.astype(float)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set values for the neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 inputs per time step ( 37 ) comprising 1 time slice, 110 features each\n"
     ]
    }
   ],
   "source": [
    "n_inputs = n_inputs_pure * pot\n",
    "\n",
    "n_units = 15\n",
    "\n",
    "n_output = 1\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "print(n_inputs, \"inputs per time step (\",n_time_steps,\") comprising\", pot, \"time slice,\", n_inputs_pure, \"features each\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 355 samples, validate on 153 samples\n",
      "Epoch 1/100\n",
      "355/355 [==============================] - 3s 8ms/step - loss: 5.1878 - val_loss: 5.3224\n",
      "Epoch 2/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 3.3150 - val_loss: 4.4308\n",
      "Epoch 3/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 2.6347 - val_loss: 3.7467\n",
      "Epoch 4/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 1.9253 - val_loss: 2.6690\n",
      "Epoch 5/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 1.2012 - val_loss: 1.8441\n",
      "Epoch 6/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.8305 - val_loss: 1.3664\n",
      "Epoch 7/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.6428 - val_loss: 1.1701\n",
      "Epoch 8/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.5550 - val_loss: 1.0726\n",
      "Epoch 9/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.5045 - val_loss: 1.0037\n",
      "Epoch 10/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.4739 - val_loss: 0.9538\n",
      "Epoch 11/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.4524 - val_loss: 0.9062\n",
      "Epoch 12/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.4294 - val_loss: 0.8192\n",
      "Epoch 13/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.4040 - val_loss: 0.7603\n",
      "Epoch 14/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3885 - val_loss: 0.7324\n",
      "Epoch 15/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3782 - val_loss: 0.7116\n",
      "Epoch 16/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3704 - val_loss: 0.6907\n",
      "Epoch 17/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3629 - val_loss: 0.6707\n",
      "Epoch 18/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3562 - val_loss: 0.6487\n",
      "Epoch 19/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3516 - val_loss: 0.6124\n",
      "Epoch 20/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3390 - val_loss: 0.5822\n",
      "Epoch 21/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3296 - val_loss: 0.5774\n",
      "Epoch 22/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3254 - val_loss: 0.5645\n",
      "Epoch 23/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3189 - val_loss: 0.5480\n",
      "Epoch 24/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3163 - val_loss: 0.5401\n",
      "Epoch 25/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3119 - val_loss: 0.5411\n",
      "Epoch 26/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3091 - val_loss: 0.5237\n",
      "Epoch 27/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3050 - val_loss: 0.5135\n",
      "Epoch 28/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3005 - val_loss: 0.5104\n",
      "Epoch 29/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2975 - val_loss: 0.4989\n",
      "Epoch 30/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2934 - val_loss: 0.4970\n",
      "Epoch 31/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2918 - val_loss: 0.4864\n",
      "Epoch 32/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2875 - val_loss: 0.4775\n",
      "Epoch 33/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2848 - val_loss: 0.4709\n",
      "Epoch 34/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2860 - val_loss: 0.4660\n",
      "Epoch 35/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2808 - val_loss: 0.4597\n",
      "Epoch 36/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2778 - val_loss: 0.4455\n",
      "Epoch 37/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2778 - val_loss: 0.4409\n",
      "Epoch 38/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2738 - val_loss: 0.4405\n",
      "Epoch 39/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2746 - val_loss: 0.4388\n",
      "Epoch 40/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2725 - val_loss: 0.4253\n",
      "Epoch 41/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2647 - val_loss: 0.4044\n",
      "Epoch 42/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2620 - val_loss: 0.3993\n",
      "Epoch 43/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2596 - val_loss: 0.4424\n",
      "Epoch 44/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2593 - val_loss: 0.3939\n",
      "Epoch 45/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2557 - val_loss: 0.3954\n",
      "Epoch 46/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2544 - val_loss: 0.3896\n",
      "Epoch 47/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2523 - val_loss: 0.3851\n",
      "Epoch 48/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2496 - val_loss: 0.3820\n",
      "Epoch 49/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2479 - val_loss: 0.3839\n",
      "Epoch 50/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2463 - val_loss: 0.3739\n",
      "Epoch 51/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2431 - val_loss: 0.3690\n",
      "Epoch 52/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2426 - val_loss: 0.3674\n",
      "Epoch 53/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2431 - val_loss: 0.3679\n",
      "Epoch 54/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2402 - val_loss: 0.3688\n",
      "Epoch 55/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2393 - val_loss: 0.3694\n",
      "Epoch 56/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2372 - val_loss: 0.3596\n",
      "Epoch 57/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2352 - val_loss: 0.3600\n",
      "Epoch 58/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2339 - val_loss: 0.3603\n",
      "Epoch 59/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2315 - val_loss: 0.3568\n",
      "Epoch 60/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2300 - val_loss: 0.3589\n",
      "Epoch 61/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2288 - val_loss: 0.3535\n",
      "Epoch 62/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2281 - val_loss: 0.3525\n",
      "Epoch 63/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2281 - val_loss: 0.3570\n",
      "Epoch 64/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2265 - val_loss: 0.3482\n",
      "Epoch 65/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2257 - val_loss: 0.3523\n",
      "Epoch 66/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2231 - val_loss: 0.3520\n",
      "Epoch 67/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2228 - val_loss: 0.3529\n",
      "Epoch 68/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2204 - val_loss: 0.3484\n",
      "Epoch 69/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2188 - val_loss: 0.3488\n",
      "Epoch 70/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 0.2185 - val_loss: 0.3477\n",
      "Epoch 71/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2168 - val_loss: 0.3439\n",
      "Epoch 72/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2155 - val_loss: 0.3523\n",
      "Epoch 73/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2155 - val_loss: 0.3445\n",
      "Epoch 74/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2139 - val_loss: 0.3439\n",
      "Epoch 75/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2119 - val_loss: 0.3454\n",
      "Epoch 76/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2136 - val_loss: 0.3472\n",
      "Epoch 77/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2123 - val_loss: 0.3474\n",
      "Epoch 78/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2102 - val_loss: 0.3465\n",
      "Epoch 79/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2087 - val_loss: 0.3390\n",
      "Epoch 80/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2069 - val_loss: 0.3447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2061 - val_loss: 0.3488\n",
      "Epoch 82/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2061 - val_loss: 0.3384\n",
      "Epoch 83/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2045 - val_loss: 0.3453\n",
      "Epoch 84/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2020 - val_loss: 0.3465\n",
      "Epoch 85/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2050 - val_loss: 0.3445\n",
      "Epoch 86/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2054 - val_loss: 0.3456\n",
      "Epoch 87/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2073 - val_loss: 0.3437\n",
      "Epoch 88/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1991 - val_loss: 0.3411\n",
      "Epoch 89/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.1971 - val_loss: 0.3421\n",
      "Epoch 90/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1967 - val_loss: 0.3412\n",
      "Epoch 91/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.1950 - val_loss: 0.3409\n",
      "Epoch 92/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1936 - val_loss: 0.3418\n",
      "Epoch 93/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1932 - val_loss: 0.3447\n",
      "Epoch 94/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1916 - val_loss: 0.3430\n",
      "Epoch 95/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.1910 - val_loss: 0.3487\n",
      "Epoch 96/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1903 - val_loss: 0.3440\n",
      "Epoch 97/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1884 - val_loss: 0.3491\n",
      "Epoch 98/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1885 - val_loss: 0.3480\n",
      "Epoch 99/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1885 - val_loss: 0.3450\n",
      "Epoch 100/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1862 - val_loss: 0.3495\n"
     ]
    }
   ],
   "source": [
    "model_adam = M.Sequential()\n",
    "\n",
    "# Each input data point has 20 timesteps, each with 26 features.\n",
    "# So the input shape (excluding batch_size) is (20, 26), which\n",
    "# matches the shape of each data point in data_x above.\n",
    "model_adam.add(L.LSTM(64, input_shape=(n_time_steps, n_inputs), return_sequences=True))\n",
    "model_adam.add(L.Dense(n_output, activation='linear'))\n",
    "\n",
    "# You need to pick appropriate loss/optimizers for your problem.\n",
    "# I'm just using these to make the example compile.\n",
    "model_adam.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "history_adam = model_adam.fit(X_train, y_train, batch_size = 32, \n",
    "                              epochs=100, validation_data=(X_test, y_test), \n",
    "                              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 355 samples, validate on 153 samples\n",
      "Epoch 1/100\n",
      "355/355 [==============================] - 3s 7ms/step - loss: 3.2053 - val_loss: 5.0773\n",
      "Epoch 2/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 1.9604 - val_loss: 1.9688\n",
      "Epoch 3/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.9012 - val_loss: 1.2591\n",
      "Epoch 4/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.6569 - val_loss: 0.9905\n",
      "Epoch 5/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.5615 - val_loss: 1.2034\n",
      "Epoch 6/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.5832 - val_loss: 0.9234\n",
      "Epoch 7/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.5199 - val_loss: 1.2063\n",
      "Epoch 8/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.5956 - val_loss: 0.7713\n",
      "Epoch 9/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.4442 - val_loss: 0.8339\n",
      "Epoch 10/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.4225 - val_loss: 0.8194\n",
      "Epoch 11/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.4318 - val_loss: 0.6690\n",
      "Epoch 12/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.4099 - val_loss: 0.6503\n",
      "Epoch 13/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3978 - val_loss: 0.6853\n",
      "Epoch 14/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.4073 - val_loss: 0.7169\n",
      "Epoch 15/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3850 - val_loss: 0.6512\n",
      "Epoch 16/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.4112 - val_loss: 0.5905\n",
      "Epoch 17/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3674 - val_loss: 0.5915\n",
      "Epoch 18/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3642 - val_loss: 0.6743\n",
      "Epoch 19/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3766 - val_loss: 0.6448\n",
      "Epoch 20/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3630 - val_loss: 0.5960\n",
      "Epoch 21/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3542 - val_loss: 0.7563\n",
      "Epoch 22/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.4147 - val_loss: 0.6080\n",
      "Epoch 23/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3612 - val_loss: 0.5432\n",
      "Epoch 24/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3516 - val_loss: 0.5271\n",
      "Epoch 25/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3441 - val_loss: 0.5156\n",
      "Epoch 26/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3362 - val_loss: 0.5293\n",
      "Epoch 27/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3360 - val_loss: 0.5190\n",
      "Epoch 28/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3414 - val_loss: 0.4900\n",
      "Epoch 29/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3296 - val_loss: 0.5746\n",
      "Epoch 30/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3436 - val_loss: 0.4865\n",
      "Epoch 31/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3275 - val_loss: 0.4720\n",
      "Epoch 32/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3204 - val_loss: 0.4904\n",
      "Epoch 33/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3227 - val_loss: 0.4608\n",
      "Epoch 34/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3153 - val_loss: 0.4587\n",
      "Epoch 35/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3143 - val_loss: 0.4594\n",
      "Epoch 36/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3154 - val_loss: 0.4841\n",
      "Epoch 37/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3126 - val_loss: 0.4515\n",
      "Epoch 38/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3170 - val_loss: 0.4870\n",
      "Epoch 39/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3181 - val_loss: 0.4848\n",
      "Epoch 40/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3193 - val_loss: 0.4588\n",
      "Epoch 41/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3098 - val_loss: 0.4645\n",
      "Epoch 42/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3088 - val_loss: 0.4493\n",
      "Epoch 43/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3087 - val_loss: 0.4527\n",
      "Epoch 44/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3065 - val_loss: 0.4441\n",
      "Epoch 45/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3074 - val_loss: 0.4401\n",
      "Epoch 46/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3019 - val_loss: 0.4347\n",
      "Epoch 47/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3001 - val_loss: 0.4297\n",
      "Epoch 48/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2985 - val_loss: 0.4536\n",
      "Epoch 49/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2981 - val_loss: 0.4253\n",
      "Epoch 50/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2964 - val_loss: 0.4388\n",
      "Epoch 51/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2945 - val_loss: 0.4184\n",
      "Epoch 52/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2921 - val_loss: 0.4290\n",
      "Epoch 53/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3000 - val_loss: 0.4205\n",
      "Epoch 54/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2918 - val_loss: 0.4213\n",
      "Epoch 55/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2891 - val_loss: 0.4103\n",
      "Epoch 56/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2877 - val_loss: 0.3996\n",
      "Epoch 57/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2869 - val_loss: 0.3987\n",
      "Epoch 58/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2855 - val_loss: 0.4415\n",
      "Epoch 59/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3018 - val_loss: 0.3958\n",
      "Epoch 60/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2854 - val_loss: 0.3939\n",
      "Epoch 61/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2857 - val_loss: 0.4034\n",
      "Epoch 62/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2842 - val_loss: 0.3868\n",
      "Epoch 63/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2850 - val_loss: 0.3859\n",
      "Epoch 64/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2805 - val_loss: 0.4030\n",
      "Epoch 65/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2813 - val_loss: 0.3919\n",
      "Epoch 66/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2805 - val_loss: 0.3826\n",
      "Epoch 67/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2800 - val_loss: 0.3803\n",
      "Epoch 68/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2779 - val_loss: 0.3942\n",
      "Epoch 69/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2805 - val_loss: 0.3754\n",
      "Epoch 70/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2758 - val_loss: 0.4131\n",
      "Epoch 71/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2791 - val_loss: 0.3742\n",
      "Epoch 72/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2754 - val_loss: 0.3914\n",
      "Epoch 73/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2755 - val_loss: 0.3701\n",
      "Epoch 74/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2736 - val_loss: 0.3772\n",
      "Epoch 75/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2731 - val_loss: 0.3662\n",
      "Epoch 76/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2722 - val_loss: 0.3702\n",
      "Epoch 77/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2728 - val_loss: 0.3857\n",
      "Epoch 78/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2768 - val_loss: 0.3632\n",
      "Epoch 79/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2700 - val_loss: 0.3636\n",
      "Epoch 80/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2702 - val_loss: 0.3683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2705 - val_loss: 0.3577\n",
      "Epoch 82/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2683 - val_loss: 0.3580\n",
      "Epoch 83/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2683 - val_loss: 0.3579\n",
      "Epoch 84/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2677 - val_loss: 0.3548\n",
      "Epoch 85/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2694 - val_loss: 0.3623\n",
      "Epoch 86/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2678 - val_loss: 0.3602\n",
      "Epoch 87/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2680 - val_loss: 0.3519\n",
      "Epoch 88/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2662 - val_loss: 0.3527\n",
      "Epoch 89/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2658 - val_loss: 0.3547\n",
      "Epoch 90/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2657 - val_loss: 0.3465\n",
      "Epoch 91/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2658 - val_loss: 0.3490\n",
      "Epoch 92/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2646 - val_loss: 0.3449\n",
      "Epoch 93/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2633 - val_loss: 0.3454\n",
      "Epoch 94/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2628 - val_loss: 0.3529\n",
      "Epoch 95/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2631 - val_loss: 0.3450\n",
      "Epoch 96/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2633 - val_loss: 0.3850\n",
      "Epoch 97/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2703 - val_loss: 0.3608\n",
      "Epoch 98/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2656 - val_loss: 0.3500\n",
      "Epoch 99/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2615 - val_loss: 0.3551\n",
      "Epoch 100/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2633 - val_loss: 0.3464\n"
     ]
    }
   ],
   "source": [
    "model_sgd = M.Sequential()\n",
    "\n",
    "\n",
    "model_sgd.add(L.LSTM(64, input_shape=(n_time_steps, n_inputs), return_sequences=True))\n",
    "model_sgd.add(L.Dense(n_output, activation='linear'))\n",
    "\n",
    "model_sgd.compile(optimizer = 'sgd', loss = 'mean_squared_error')\n",
    "\n",
    "history_sgd = model_sgd.fit(X_train, y_train, batch_size = 32, \n",
    "                              epochs=100, validation_data=(X_test, y_test), \n",
    "                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_test_sgd = history_sgd.__dict__['history']['val_loss']\n",
    "mse_train_sgd = history_sgd.__dict__['history']['loss']\n",
    "sgd_params = history_sgd.__dict__['params']\n",
    "\n",
    "mse_test_adam = history_adam.__dict__['history']['val_loss']\n",
    "mse_train_adam = history_adam.__dict__['history']['loss']\n",
    "adam_params = history_adam.__dict__['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Train Scores\n",
      "SGD 0.26153172808633723\n",
      "SGD epoch: 98\n",
      "Adam 0.18620200333460957\n",
      "Adam epoch: 99\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mse_train_adam)\n",
    "plt.plot(mse_train_sgd)\n",
    "\n",
    "plt.legend(['train_adam','train_sgd'])\n",
    "\n",
    "print(\"Best Train Scores\")\n",
    "print(\"SGD\", np.min(mse_train_sgd))\n",
    "print(\"SGD epoch:\",np.argmin(mse_train_sgd))\n",
    "\n",
    "print(\"Adam\", np.min(mse_train_adam))\n",
    "print(\"Adam epoch:\",np.argmin(mse_train_adam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Test Scores\n",
      "SGD 0.3448968284270343\n",
      "SGD epoch: 91\n",
      "Adam 0.338403881570093\n",
      "Adam epoch: 81\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mse_test_adam)\n",
    "plt.plot(mse_test_sgd)\n",
    "\n",
    "plt.legend(['test_adam','test_sgd'])\n",
    "\n",
    "print(\"Best Test Scores\")\n",
    "print(\"SGD\", np.min(mse_test_sgd))\n",
    "print(\"SGD epoch:\", np.argmin(mse_test_sgd))\n",
    "\n",
    "print(\"Adam\", np.min(mse_test_adam))\n",
    "print(\"Adam epoch:\", np.argmin(mse_test_adam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_df = pd.concat([pd.DataFrame(mse_test_adam, columns=['Adam Test MSE']),\n",
    "pd.DataFrame(mse_test_sgd, columns=['SGD Test MSE']),\n",
    "pd.DataFrame(mse_train_adam, columns=['Adam Train MSE']),\n",
    "pd.DataFrame(mse_train_sgd, columns=['SGD Train MSE'])], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_df.to_csv('LSTM_df_parametrization.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
