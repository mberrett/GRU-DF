{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU-DF â€” 6m observation window\n",
    "### Prediction Imputation\n",
    "\n",
    "- For this model we do not mask the training set's missing instances. We impute them.\n",
    "- We do, however, perform masking for the teting data evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updates\n",
    "- Remove all test operations\n",
    "- mask_list.append((train, test)) went to mask_list.append(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import sklearn as sk\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "from keras import callbacks\n",
    "import keras.layers as L\n",
    "import keras.models as M\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "import os, shutil\n",
    "\n",
    "from keras.regularizers import l1_l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     7,
     11,
     26,
     39,
     60,
     69,
     85,
     97
    ]
   },
   "outputs": [],
   "source": [
    "def select_columns(col_list, n_months):\n",
    "    \"\"\"\n",
    "    Takes in a list of column names and number of visits starting at 0.\n",
    "    Returns column list time-stepped and dovetailed.\n",
    "    \"\"\" \n",
    "    return dovetail_names(*[time_step_names(i, n_months) for i in col_list])\n",
    "        \n",
    "def time_step_names(name, n_months):\n",
    "\n",
    "    return [(name + '_%d' % (j+1)) for j in range(-1,n_months*6, 6)]\n",
    "\n",
    "def dovetail_names(*kwargs):\n",
    "    \"\"\"\n",
    "    Dovetails column names across time slices cccording to preset order.\n",
    "    \"\"\"\n",
    "    zipped = zip(*kwargs)\n",
    "    l = []\n",
    "   \n",
    "    for i in zipped:\n",
    "        \n",
    "        for j in i:\n",
    "            \n",
    "            l.append(j)\n",
    "            \n",
    "    return l\n",
    "\n",
    "def reshape_data(X, y, n_time_steps, n_features = 115):  \n",
    "    \n",
    "    X_reshaped = X.values.reshape(-1, n_time_steps, n_features)\n",
    "    y_reshaped = y.values.reshape(-1, n_time_steps, 1)\n",
    "    print(\"X reshaped is \" + str(X_reshaped.shape))\n",
    "    print(\"y reshaped is \" + str(y_reshaped.shape))\n",
    "\n",
    "    y = y_reshaped.astype(float)\n",
    "    X = X_reshaped.astype(float)\n",
    "    \n",
    "    print(X.shape, y.shape)\n",
    "    return X, y\n",
    "\n",
    "def provide_data(X,y,roll,n_features=115):\n",
    " \n",
    "    X = X.iloc[:,:n_features*roll]\n",
    "    y = y.iloc[:,:roll]\n",
    "\n",
    "    y_full = y.dropna()\n",
    "\n",
    "    mask = X.index.isin(y_full.index.tolist())\n",
    "\n",
    "    X_full = X[mask]\n",
    "\n",
    "    y_nan = y[~mask]\n",
    "    X_nan = X[~mask]\n",
    "    \n",
    "    print('NaN')\n",
    "    X_nan, y_nan = reshape_data(X_nan, y_nan, roll)\n",
    "    print('Full')\n",
    "    X_full, y_full = reshape_data(X_full, y_full, roll)\n",
    "    \n",
    "    return X_full, X_nan, y_full, y_nan, mask\n",
    "\n",
    "def provide_all_data(X,y,roll):\n",
    " \n",
    "    X = X.iloc[:,:n_features*roll]\n",
    "    y = y.iloc[:,:roll]\n",
    "\n",
    "    X_all, y_all = reshape_data(X, y, roll)\n",
    "    \n",
    "    return X_all, y_all\n",
    "    \n",
    "def prepare_for_mask(X,y, mask_value = -99):\n",
    "    \n",
    "    for i in range(y.shape[0]):\n",
    "        for j in range(y.shape[1]):\n",
    "            if np.isnan(y[i][j][0]) or (y[i][j] == mask_value):\n",
    "\n",
    "                X[i][j] = mask_value\n",
    "                y[i][j] = mask_value\n",
    "                \n",
    "            if (mask_value in X[i][j]) or np.isnan(X[i][j][114]):\n",
    "                \n",
    "                X[i][j] = mask_value\n",
    "                y[i][j] = mask_value\n",
    "            \n",
    "    return X,y\n",
    "\n",
    "def round_off_EDSS(number):\n",
    "    \"\"\"Round a number to the closest half integer.\n",
    "    >>> round_of_rating(1.3)\n",
    "    1.5\n",
    "    >>> round_of_rating(2.6)\n",
    "    2.5\n",
    "    >>> round_of_rating(3.0)\n",
    "    3.0\n",
    "    >>> round_of_rating(4.1)\n",
    "    4.0\"\"\"\n",
    "    return np.round(number * 2) / 2\n",
    "   \n",
    "def def_train_name(f_ix):\n",
    "    \n",
    "    X_train_name = \"data_folds/X_train_f\" + str(f_ix + 1) + \".csv\"\n",
    "    y_train_name = \"data_folds/y_train_f\" + str(f_ix + 1) + \".csv\"\n",
    "    X_test_name = \"data_folds/X_test_f\" + str(f_ix + 1) + \".csv\"\n",
    "    y_test_name = \"data_folds/y_test_f\" + str(f_ix + 1) + \".csv\"\n",
    "    \n",
    "    return X_train_name, X_test_name, y_train_name, y_test_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     5,
     9,
     14
    ]
   },
   "outputs": [],
   "source": [
    "weight_file_path = \"weights/my_model_weights_6m.h5\"\n",
    "final_file_path = \"final_weights/my_model_weights_6m.h5\"\n",
    "best_file_path = \"best/best_weights_6m.hdf5\"\n",
    "\n",
    "# reduce learning rate on plateau\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                               patience=5, min_lr=0.001)\n",
    "\n",
    "# stop training if there isn't a significant improvement in the course of 5 epochs\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, \n",
    "                              patience=5, verbose=0, mode='auto', \n",
    "                              baseline=None, restore_best_weights=True)\n",
    "\n",
    "# model check point\n",
    "model_checkpoint = ModelCheckpoint(best_file_path, monitor='val_loss', \n",
    "                                   verbose=1, \n",
    "                                   save_best_only=True, \n",
    "                                   mode='min')\n",
    "\n",
    "callbacks_list = [reduce_lr, early_stopping]\n",
    "callbacks_list_final = [reduce_lr, early_stopping, model_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def rnn_model(n_time_steps, n_inputs):\n",
    "    \n",
    "    m = M.Sequential()\n",
    "    m.add(L.Masking(mask_value=-99, input_shape=(n_time_steps, n_inputs)))\n",
    "    m.add(L.GRU(128, return_sequences=True))\n",
    "    m.add(L.Dropout(0.2))\n",
    "    m.add(L.Dense(1, activation='relu'))\n",
    "    m.compile(optimizer = 'adam', loss = 'mean_absolute_error')\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     45,
     69,
     80
    ]
   },
   "outputs": [],
   "source": [
    "def optimal_test_model(X_train, y_train, n_features=115, pot = 1):\n",
    "    \n",
    "    \"\"\"STEP 3, PART A\n",
    "    Determine optimal model to evalute test data\n",
    "    now that the data sets are already imputed\"\"\"\n",
    "    # Delete Previous Model Checkpoint, if any\n",
    "    if os.path.exists('optimal_weights_6m/'):\n",
    "        shutil.rmtree('optimal_weights_6m/')\n",
    "    os.makedirs('optimal_weights_6m/')\n",
    "        \n",
    "    optimal_file_path = \"optimal_weights_6m/weights_6m.hdf5\"\n",
    "    \n",
    "    model_checkpoint = ModelCheckpoint(optimal_file_path, \n",
    "                                       monitor='val_loss', \n",
    "                                       verbose=1, \n",
    "                                       save_best_only=True, mode='min')\n",
    "\n",
    "    callbacks_list = [reduce_lr, early_stopping, model_checkpoint]\n",
    "\n",
    "    \"\"\"Running the model after we've imputed for the whole feature space\"\"\"\n",
    "    \n",
    "    n_inputs = n_features*pot\n",
    "    n_time_steps = len(y_train.columns)\n",
    "    \n",
    "    X_train_all, y_train_all = provide_all_data(X_train, y_train, n_time_steps)\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    m = rnn_model(n_time_steps, n_inputs)\n",
    "    \n",
    "    m.fit(X_train_all, y_train_all,\n",
    "                    validation_split = 0.2,\n",
    "                    batch_size = 32, \n",
    "                    epochs=100,\n",
    "                    shuffle=True,\n",
    "                   callbacks = callbacks_list)\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    m = rnn_model(n_time_steps, n_inputs)\n",
    "    # load weights from previous model to establish continuity \n",
    "    m.load_weights(optimal_file_path)\n",
    "    \n",
    "    return m\n",
    "\n",
    "def evaluate_model(X_train, X_test, y_train, y_test): \n",
    "    \"\"\"\n",
    "    STEP 3 PART B\n",
    "    Evaluate model with held out test set\n",
    "    \"\"\"\n",
    "    \n",
    "    m = optimal_test_model(X_train, y_train)\n",
    "    \n",
    "    n_time_steps = len(y_train.columns)\n",
    "    \n",
    "    X_test_all, y_test_all = provide_all_data(X_test, y_test, n_time_steps)\n",
    "    \n",
    "    masked_X_test_all, masked_y_test_all = prepare_for_mask(X_test_all, y_test_all)\n",
    "    \n",
    "    y_pred = round_off_EDSS(m.predict(masked_X_test_all))\n",
    "    \n",
    "    mask_test = np.where(masked_y_test_all.reshape(-1) != -99)\n",
    "    \n",
    "    res = mae(y_pred.reshape(-1)[mask_test], masked_y_test_all.reshape(-1)[mask_test])\n",
    "    \n",
    "    print(res)\n",
    "    \n",
    "    return res\n",
    "\n",
    "def retrieve_fold(f_ix):\n",
    "\n",
    "    X_train_name, X_test_name, y_train_name, y_test_name = def_train_name(f_ix)\n",
    "    \n",
    "    X_train = pd.read_csv(X_train_name,  index_col = 0)\n",
    "    X_test = pd.read_csv(X_test_name,  index_col = 0)\n",
    "    y_train = pd.read_csv(y_train_name,  index_col = 0)\n",
    "    y_test = pd.read_csv(y_test_name, index_col = 0)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "def kfold_eval(f_ix, ahead):\n",
    "    \n",
    "    less = ahead - 1\n",
    "    \n",
    "    l = []\n",
    "\n",
    "    for fold in range(5):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = retrieve_fold(fold)\n",
    "        \n",
    "        if ahead > 1:\n",
    "            \n",
    "            res = evaluate_model(X_train.iloc[:,:-(less*115)],\n",
    "                             X_test.iloc[:,:-(less*115)], \n",
    "                             y_train.iloc[:,less:], \n",
    "                             y_test.iloc[:,less:])\n",
    "        else:\n",
    "            \n",
    "            res = evaluate_model(X_train,\n",
    "                             X_test,\n",
    "                             y_train,\n",
    "                             y_test)\n",
    "        \n",
    "        print(\"Fold #\", str(fold+1), \": \", str(res))\n",
    "        l.append(res)\n",
    "        \n",
    "    return np.mean(l)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 115\n",
    "pot = 1\n",
    "n_inputs = n_features * pot\n",
    "n_units = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = kfold_eval(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = kfold_eval(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = kfold_eval(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result4 = kfold_eval(1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result5 = kfold_eval(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result6 = kfold_eval(1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result7 = kfold_eval(1,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result8 = kfold_eval(1,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result9 = kfold_eval(1,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result10 = kfold_eval(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result11 = kfold_eval(1,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result12 = kfold_eval(1,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result12"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
