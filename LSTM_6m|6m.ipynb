{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM_RNN\n",
    "\n",
    "### 6 months | 6 months\n",
    "\n",
    "### target: EDSS_6...EDSS_222\n",
    "- Time Steps: 37\n",
    "- Evaluation: MSE \n",
    "- Imputation: Zero Imputation\n",
    "- Features: Optimal 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matiasberretta/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import sklearn as sk\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns(col_list, n_months):\n",
    "    \n",
    "    \"\"\"takes in a list of column names and number of visits starting at 0\n",
    "    returns column list time-stepped and dovetailed\"\"\" \n",
    "    \n",
    "    return dovetail_names(*[time_step_names(i, n_months) for i in col_list])\n",
    "        \n",
    "def time_step_names(name, n_months):\n",
    "\n",
    "    return [(name + '_%d' % (j+1)) for j in range(-1,n_months*6, 6)]\n",
    "\n",
    "def dovetail_names(*kwargs):\n",
    "    zipped = zip(*kwargs)\n",
    "    l = []\n",
    "    for i in zipped:\n",
    "        for j in i:\n",
    "            l.append(j)\n",
    "    return l\n",
    "\n",
    "def stretch_input(Xtr, n_inputs, time_steps, pot):\n",
    "\n",
    "    \"\"\"Xtr_fill is empty 3D numpy array where we extend length of patient observation times t\n",
    "    pot stands for Patient Observation Time. We only need to do this for our X input\"\"\"\n",
    "    \n",
    "    Xtr_fill = np.zeros(shape=[Xtr.shape[0],time_steps,n_inputs*pot] , dtype = object) \n",
    "\n",
    "    for subject in range(Xtr.shape[0]):\n",
    "    \n",
    "        for i in range(time_steps):\n",
    "\n",
    "            temp = np.concatenate([Xtr[subject][i],Xtr[subject][i+1]]) # changed for pot = 3\n",
    "            Xtr_fill[subject][i] = temp\n",
    "            \n",
    "    return Xtr_fill\n",
    "\n",
    "def stack_times(data, name, n):\n",
    "    \n",
    "    \n",
    "    \"\"\"takes in dataframe, column name and n of time steps\n",
    "    and puts it in long format\"\"\"\n",
    "    \n",
    "    all_names = select_columns(name, n-1)\n",
    "    \n",
    "    l = []\n",
    "    \n",
    "    for col in all_names:\n",
    "        l.append(data[col].copy())\n",
    "    \n",
    "    stacked = l[0]\n",
    "    rest = l[1:]\n",
    "    \n",
    "    # stack Series and get dummy variables \n",
    "    stacked.append(rest)\n",
    "    \n",
    "    return stacked\n",
    "\n",
    "def stack_dummy(data, name, n):\n",
    "    \n",
    "    \n",
    "    \"\"\"takes in dataframe and column name\n",
    "    return that same feature split into dummy columns\n",
    "    across n time steps (adjacent)\"\"\"\n",
    "    \n",
    "    all_names = select_columns(name, n-1)\n",
    "    \n",
    "    l = []\n",
    "    \n",
    "    for col in all_names:\n",
    "        l.append(data[col].copy())\n",
    "    \n",
    "    f = l[0]\n",
    "    rest = l[1:]\n",
    "    \n",
    "    # stack Series and get dummy variables \n",
    "    pre_dummy = pd.get_dummies(f.append(rest))\n",
    "    \n",
    "    after_dummy = time_dummy(pre_dummy, n)\n",
    "    \n",
    "    dummy_value_names = generate_col_names(after_dummy, name)\n",
    "    time_stepped_dummy_names = time_step_dummy_value_names(dummy_value_names, n)\n",
    "    \n",
    "    for t in range(len(after_dummy)):\n",
    "        \n",
    "        after_dummy[t].columns = list(time_stepped_dummy_names[t])\n",
    "        \n",
    "    #untimed_names_to_order = column_names_per_time_step(col_names_together, \"what are you\", name[0])\n",
    "    #names_to_order = select_columns(untimed_names_to_order, n-1)\n",
    "\n",
    "    return pd.concat(after_dummy, axis = 1, sort = False), dummy_value_names\n",
    "\n",
    "\n",
    "def time_dummy(dummy_df, n):\n",
    "    \n",
    "    \"\"\"Separates long data frame into time steps \n",
    "    (508 subjects (rows) per time step)\"\"\"\n",
    "    \n",
    "    l = []\n",
    "    for i in range(n):\n",
    "        l.append(dummy_df.iloc[i*508:(i+1)*508,:].copy())\n",
    "    \n",
    "    return l\n",
    "\n",
    "def generate_col_names(after_dummy, name):\n",
    "    \n",
    "    \"\"\"Generates column names for result of pd.get_dummies on a feature\n",
    "    i.e. if A has values x and y, it will generate A_x, A_y\"\"\"\n",
    "    \n",
    "    return [(str(name[0]) + \"_\" + str(list(after_dummy[0].columns)[i])) for i in range(len(list(after_dummy[0].columns)))]\n",
    "\n",
    "def time_step_dummy_value_names(names, n_months):\n",
    "    \n",
    "    long_list = [(name + '_%d' % (j+1)) for j in range(-1,n_months*6, 6) for name in names]\n",
    "    return np.array(long_list).reshape(-1, len(names))\n",
    "\n",
    "def add_columns(add_to, name, names_per_t, n):\n",
    "    \n",
    "    n = n + 1\n",
    "    to_add, bare_names = stack_dummy(df, name, n)\n",
    "    to_remove = select_columns(name, n-1)\n",
    "    \n",
    "    \"\"\"add new dummied features to dataframes (copy)\n",
    "    and remove undummied version of features\n",
    "    name is a list\n",
    "    \n",
    "    encompasses stack_dummy\"\"\"\n",
    "    \n",
    "    newdf = add_to.copy()\n",
    "    column_names = list(to_add.columns)\n",
    "    \n",
    "    for i in range(len(column_names)):\n",
    "        newdf[column_names[i]] = to_add.iloc[:,i]\n",
    "    newdf.drop(to_remove,axis = 1, inplace = True)\n",
    "    \n",
    "    #print(bare_names, name[0])\n",
    "    \n",
    "    names_per_t_updated = column_names_per_time_step(names_per_t, bare_names, name[0])\n",
    "    namesOrder= select_columns(names_per_t_updated, n-1)\n",
    "    return newdf[namesOrder].copy(), names_per_t_updated\n",
    "\n",
    "#    return names_per_t_updated\n",
    "#     print(name[0])\n",
    "    \n",
    "    \n",
    "    return newdf[namesOrder].copy(), names_per_t_updated\n",
    "\n",
    "\n",
    "def column_names_per_time_step(original_list, add, remove):\n",
    "    \"\"\"makes sure EDSS stays at the end\n",
    "    remove pre \"\"\"\n",
    "    \n",
    "    new_list = original_list.copy()\n",
    "    \n",
    "    \n",
    "    new_list.remove(remove)\n",
    "    new_list.extend(add)\n",
    "    \n",
    "    # makes sure EDSS is always last\n",
    "    \n",
    "    new_list.remove('EDSS')\n",
    "    new_list.append('EDSS')\n",
    "    \n",
    "    return new_list\n",
    "\n",
    "def manual_dummy(df, names, name_list, n):\n",
    "    \n",
    "    dfUpdated =df.copy()\n",
    "    names = [[name] for name in names] # turn to list foramt so that it works\n",
    "    \n",
    "    for name in names:\n",
    "        \n",
    "        dfUpdated, name_list = add_columns(dfUpdated, name , name_list, n)\n",
    "   \n",
    "    return dfUpdated # should I return name_list as well?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATA & DEFINE N OF TIME STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xold = pd.read_csv(\"data/X_6_months|6_months_exhaustive.csv\", index_col = 0)\n",
    "y = pd.read_csv(\"data/y_6_months|6_months_exhaustive.csv\", index_col = 0)\n",
    "\n",
    "predictive_features = pd.read_csv(\"predictive_features_list.csv\", index_col = 0, header = None)\n",
    "predictive_features_list = predictive_features[1].values.tolist()\n",
    "\n",
    "n_time_steps = len(y.columns)\n",
    "pot = 1\n",
    "print(\"The RNN window will slide\", n_time_steps, \"times\")\n",
    "print(\"The input length of the training data will be\", pot, \"time slices, separated by 6 month intervals\")\n",
    "\n",
    "n_inputs_pure = len(predictive_features_list)\n",
    "print(n_inputs_pure, \"optimal featues\")\n",
    "predictive_features_list_timed = select_columns(predictive_features_list, n_time_steps-1)\n",
    "\n",
    "X = Xold[predictive_features_list_timed].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
    "\n",
    "# X train n_time_steps will be +1 to account for stretching\n",
    "# which will turn 11 time slices of 1 to 10 time slices of 2\n",
    "X_train_reshaped = X_train.values.reshape(-1, n_time_steps, n_inputs_pure) # extra time step for stretch\n",
    "y_train_reshaped = y_train.values.reshape(-1, n_time_steps, 1)\n",
    "print(\"X reshaped is \" + str(X_train_reshaped.shape))\n",
    "print(\"y reshaped is \" + str(y_train_reshaped.shape))\n",
    "\n",
    "X_test_reshaped = X_test.values.reshape(-1, n_time_steps, n_inputs_pure)\n",
    "y_test_reshaped = y_test.values.reshape(-1, n_time_steps, 1)\n",
    "print(\"X reshaped is \" + str(X_test_reshaped.shape))\n",
    "print(\"y reshaped is \" + str(y_test_reshaped.shape))\n",
    "\n",
    "y_train = y_train_reshaped.astype(float)\n",
    "y_test = y_test_reshaped.astype(float)\n",
    "X_train = X_train_reshaped.astype(float)\n",
    "X_test = X_test_reshaped.astype(float)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set values for the neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 inputs per time step ( 37 ) comprising 1 time slices, 26 features each\n"
     ]
    }
   ],
   "source": [
    "n_inputs = n_inputs_pure * pot\n",
    "\n",
    "n_neurons = 15\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "n_steps = n_time_steps\n",
    "\n",
    "print(n_inputs, \"inputs per time step (\",n_steps,\") comprising\", pot, \"time slices,\", n_inputs_pure, \"features each\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as reshaping X_train, X_test, y_train, y_test, etc... except that instead of -1, we use None\n",
    "X_tf = tf.placeholder(tf.float32, [None, n_time_steps, n_inputs], name = \"X\") # [None, 8, 27]\n",
    "y_tf = tf.placeholder(tf.float32, [None, n_time_steps, 1], name = \"y\") # changed from tf.float32 to tf.int32 \n",
    "\n",
    "lstm_cell = tf.contrib.rnn.LSTMCell(num_units = n_neurons, use_peepholes = True)\n",
    "output_seqs, (c_states, h_states) = tf.nn.dynamic_rnn(lstm_cell, X_tf, dtype = tf.float32)\n",
    "\n",
    "predictions = tf.contrib.layers.fully_connected(output_seqs, 1, activation_fn=tf.nn.relu)\n",
    "\n",
    "loss = tf.losses.mean_squared_error(labels = y_tf, predictions = predictions)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "n_epochs = 30\n",
    "batch_sz = 100\n",
    "mse_train = []\n",
    "mse_test = []\n",
    "allpredictions = []\n",
    "alloutputs = []\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iter in range(len(X_train) // batch_sz):\n",
    "\n",
    "            X_batch, y_batch = X_train[iter*batch_sz: (iter+1)*batch_sz], y_train[iter*batch_sz: (iter+1)*batch_sz]\n",
    "            X_batch = X_batch.reshape(-1, n_steps, n_inputs)\n",
    "            y_batch = y_batch.reshape(-1,n_steps, 1) # added 1\n",
    "            sess.run(training_op, feed_dict={X_tf: X_batch, y_tf: y_batch})\n",
    "                \n",
    "        \n",
    "        mse_train.append(sess.run(loss, feed_dict={X_tf: X_batch, y_tf: y_batch}))\n",
    "    \n",
    "        X_test_batch = X_test.reshape(-1, n_steps, n_inputs)\n",
    "        y_test_batch = y_test.reshape(-1,n_steps,1)   \n",
    "        \n",
    "        mse_test.append(sess.run(loss, feed_dict={X_tf : X_test_batch, y_tf : y_test_batch}))\n",
    "        \n",
    "        allpredictions.append(sess.run(predictions, feed_dict={X_tf: X_test_batch}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass all mse test at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.2914845 Test MSE: 0.34756768\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mse_train)\n",
    "plt.plot(mse_test)\n",
    "plt.legend(['train','test'])\n",
    "\n",
    "print(\"Train MSE:\", mse_train[-1], \"Test MSE:\", mse_test[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34756768\n",
      "epoch: 29\n"
     ]
    }
   ],
   "source": [
    "print(np.min(mse_test))\n",
    "print(\"epoch:\",np.argmin(mse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(508, 37) (153, 37, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test.shape == allpredictions[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EDSS_6</th>\n",
       "      <th>EDSS_12</th>\n",
       "      <th>EDSS_18</th>\n",
       "      <th>EDSS_24</th>\n",
       "      <th>EDSS_30</th>\n",
       "      <th>EDSS_36</th>\n",
       "      <th>EDSS_42</th>\n",
       "      <th>EDSS_48</th>\n",
       "      <th>EDSS_54</th>\n",
       "      <th>EDSS_60</th>\n",
       "      <th>...</th>\n",
       "      <th>EDSS_168</th>\n",
       "      <th>EDSS_174</th>\n",
       "      <th>EDSS_180</th>\n",
       "      <th>EDSS_186</th>\n",
       "      <th>EDSS_192</th>\n",
       "      <th>EDSS_198</th>\n",
       "      <th>EDSS_204</th>\n",
       "      <th>EDSS_210</th>\n",
       "      <th>EDSS_216</th>\n",
       "      <th>EDSS_222</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EDSS_6  EDSS_12  EDSS_18  EDSS_24  EDSS_30  EDSS_36  EDSS_42  EDSS_48  \\\n",
       "0     6.0      6.0      6.0      6.0      6.0      6.5      6.0      6.0   \n",
       "1     0.0      0.0      0.0      2.5      1.5      1.5      1.5      1.5   \n",
       "2     4.0      4.0      4.0      4.0      3.5      3.0      3.0      5.5   \n",
       "3     4.0      5.5      4.5      3.5      3.5      3.0      3.7      4.4   \n",
       "4     3.0      2.0      3.0      3.0      6.0      4.0      4.0      4.0   \n",
       "\n",
       "   EDSS_54  EDSS_60    ...     EDSS_168  EDSS_174  EDSS_180  EDSS_186  \\\n",
       "0      6.0      1.5    ...          6.0       6.0       6.0       6.0   \n",
       "1      1.5      1.0    ...          1.0       1.0       1.0       1.0   \n",
       "2      5.5      5.5    ...          5.5       5.5       5.5       5.5   \n",
       "3      5.1      5.8    ...          7.0       7.0       7.0       7.0   \n",
       "4      3.5      3.5    ...          6.5       6.5       6.5       6.5   \n",
       "\n",
       "   EDSS_192  EDSS_198  EDSS_204  EDSS_210  EDSS_216  EDSS_222  \n",
       "0       6.0       6.0       6.0       6.0       6.0       6.0  \n",
       "1       1.0       1.0       1.0       1.0       1.0       1.0  \n",
       "2       5.5       5.5       5.5       5.5       5.5       5.5  \n",
       "3       7.0       7.0       7.0       7.0       7.0       7.0  \n",
       "4       6.5       6.5       6.5       6.5       6.5       6.5  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
