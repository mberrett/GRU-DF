{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM_RNN\n",
    "Comparing SGD vs Adam Optimizer\n",
    "\n",
    "### Model\n",
    "- model = LSTM\n",
    "- batch_size = 32\n",
    "- epochs = 100\n",
    "- loss = mse\n",
    "\n",
    "\n",
    "### Data\n",
    "- 6 months | 6 months\n",
    "- target: EDSS_6...EDSS_222\n",
    "- imputation \n",
    "    - target: interpolation (trailing ends for extrapolation)\n",
    "    - features: zero-imputation\n",
    "- time steps: exhaustive (37)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matiasberretta/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import sklearn as sk\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import keras.layers as L\n",
    "import keras.models as M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns(col_list, n_months):\n",
    "    \n",
    "    \"\"\"takes in a list of column names and number of visits starting at 0\n",
    "    returns column list time-stepped and dovetailed\"\"\" \n",
    "    \n",
    "    return dovetail_names(*[time_step_names(i, n_months) for i in col_list])\n",
    "        \n",
    "def time_step_names(name, n_months):\n",
    "\n",
    "    return [(name + '_%d' % (j+1)) for j in range(-1,n_months*6, 6)]\n",
    "\n",
    "def dovetail_names(*kwargs):\n",
    "    zipped = zip(*kwargs)\n",
    "    l = []\n",
    "    for i in zipped:\n",
    "        for j in i:\n",
    "            l.append(j)\n",
    "    return l\n",
    "\n",
    "def stretch_input(Xtr, n_inputs, time_steps, pot):\n",
    "\n",
    "    \"\"\"Xtr_fill is empty 3D numpy array where we extend length of patient observation times t\n",
    "    pot stands for Patient Observation Time. We only need to do this for our X input\"\"\"\n",
    "    \n",
    "    Xtr_fill = np.zeros(shape=[Xtr.shape[0],time_steps,n_inputs*pot] , dtype = object) \n",
    "\n",
    "    for subject in range(Xtr.shape[0]):\n",
    "    \n",
    "        for i in range(time_steps):\n",
    "\n",
    "            temp = np.concatenate([Xtr[subject][i],Xtr[subject][i+1]]) # changed for pot = 3\n",
    "            Xtr_fill[subject][i] = temp\n",
    "            \n",
    "    return Xtr_fill\n",
    "\n",
    "def stack_times(data, name, n):\n",
    "    \n",
    "    \n",
    "    \"\"\"takes in dataframe, column name and n of time steps\n",
    "    and puts it in long format\"\"\"\n",
    "    \n",
    "    all_names = select_columns(name, n-1)\n",
    "    \n",
    "    l = []\n",
    "    \n",
    "    for col in all_names:\n",
    "        l.append(data[col].copy())\n",
    "    \n",
    "    stacked = l[0]\n",
    "    rest = l[1:]\n",
    "    \n",
    "    # stack Series and get dummy variables \n",
    "    stacked.append(rest)\n",
    "    \n",
    "    return stacked\n",
    "\n",
    "def stack_dummy(data, name, n):\n",
    "    \n",
    "    \n",
    "    \"\"\"takes in dataframe and column name\n",
    "    return that same feature split into dummy columns\n",
    "    across n time steps (adjacent)\"\"\"\n",
    "    \n",
    "    all_names = select_columns(name, n-1)\n",
    "    \n",
    "    l = []\n",
    "    \n",
    "    for col in all_names:\n",
    "        l.append(data[col].copy())\n",
    "    \n",
    "    f = l[0]\n",
    "    rest = l[1:]\n",
    "    \n",
    "    # stack Series and get dummy variables \n",
    "    pre_dummy = pd.get_dummies(f.append(rest))\n",
    "    \n",
    "    after_dummy = time_dummy(pre_dummy, n)\n",
    "    \n",
    "    dummy_value_names = generate_col_names(after_dummy, name)\n",
    "    time_stepped_dummy_names = time_step_dummy_value_names(dummy_value_names, n)\n",
    "    \n",
    "    for t in range(len(after_dummy)):\n",
    "        \n",
    "        after_dummy[t].columns = list(time_stepped_dummy_names[t])\n",
    "        \n",
    "    #untimed_names_to_order = column_names_per_time_step(col_names_together, \"what are you\", name[0])\n",
    "    #names_to_order = select_columns(untimed_names_to_order, n-1)\n",
    "\n",
    "    return pd.concat(after_dummy, axis = 1, sort = False), dummy_value_names\n",
    "\n",
    "\n",
    "def time_dummy(dummy_df, n):\n",
    "    \n",
    "    \"\"\"Separates long data frame into time steps \n",
    "    (508 subjects (rows) per time step)\"\"\"\n",
    "    \n",
    "    l = []\n",
    "    for i in range(n):\n",
    "        l.append(dummy_df.iloc[i*508:(i+1)*508,:].copy())\n",
    "    \n",
    "    return l\n",
    "\n",
    "def generate_col_names(after_dummy, name):\n",
    "    \n",
    "    \"\"\"Generates column names for result of pd.get_dummies on a feature\n",
    "    i.e. if A has values x and y, it will generate A_x, A_y\"\"\"\n",
    "    \n",
    "    return [(str(name[0]) + \"_\" + str(list(after_dummy[0].columns)[i])) for i in range(len(list(after_dummy[0].columns)))]\n",
    "\n",
    "def time_step_dummy_value_names(names, n_months):\n",
    "    \n",
    "    long_list = [(name + '_%d' % (j+1)) for j in range(-1,n_months*6, 6) for name in names]\n",
    "    return np.array(long_list).reshape(-1, len(names))\n",
    "\n",
    "def add_columns(add_to, name, names_per_t, n):\n",
    "    \n",
    "    n = n + 1\n",
    "    to_add, bare_names = stack_dummy(df, name, n)\n",
    "    to_remove = select_columns(name, n-1)\n",
    "    \n",
    "    \"\"\"add new dummied features to dataframes (copy)\n",
    "    and remove undummied version of features\n",
    "    name is a list\n",
    "    \n",
    "    encompasses stack_dummy\"\"\"\n",
    "    \n",
    "    newdf = add_to.copy()\n",
    "    column_names = list(to_add.columns)\n",
    "    \n",
    "    for i in range(len(column_names)):\n",
    "        newdf[column_names[i]] = to_add.iloc[:,i]\n",
    "    newdf.drop(to_remove,axis = 1, inplace = True)\n",
    "    \n",
    "    #print(bare_names, name[0])\n",
    "    \n",
    "    names_per_t_updated = column_names_per_time_step(names_per_t, bare_names, name[0])\n",
    "    namesOrder= select_columns(names_per_t_updated, n-1)\n",
    "    return newdf[namesOrder].copy(), names_per_t_updated\n",
    "\n",
    "#    return names_per_t_updated\n",
    "#     print(name[0])\n",
    "    \n",
    "    \n",
    "    return newdf[namesOrder].copy(), names_per_t_updated\n",
    "\n",
    "\n",
    "def column_names_per_time_step(original_list, add, remove):\n",
    "    \"\"\"makes sure EDSS stays at the end\n",
    "    remove pre \"\"\"\n",
    "    \n",
    "    new_list = original_list.copy()\n",
    "    \n",
    "    \n",
    "    new_list.remove(remove)\n",
    "    new_list.extend(add)\n",
    "    \n",
    "    # makes sure EDSS is always last\n",
    "    \n",
    "    new_list.remove('EDSS')\n",
    "    new_list.append('EDSS')\n",
    "    \n",
    "    return new_list\n",
    "\n",
    "def manual_dummy(df, names, name_list, n):\n",
    "    \n",
    "    dfUpdated =df.copy()\n",
    "    names = [[name] for name in names] # turn to list foramt so that it works\n",
    "    \n",
    "    for name in names:\n",
    "        \n",
    "        dfUpdated, name_list = add_columns(dfUpdated, name , name_list, n)\n",
    "   \n",
    "    return dfUpdated # should I return name_list as well?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATA & DEFINE N OF TIME STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RNN window will slide 37 times\n",
      "The input length of the training data will be 1 time slices, separated by 6 month intervals\n",
      "There will be 110 per time step\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv(\"data/X_6_months|6_months_exhaustive.csv\", index_col = 0)\n",
    "y = pd.read_csv(\"data/y_6_months|6_months_exhaustive.csv\", index_col = 0)\n",
    "\n",
    "predictive_features = pd.read_csv(\"predictive_features_list.csv\", index_col = 0, header = None)\n",
    "predictive_features_list = predictive_features[1].values.tolist()\n",
    "\n",
    "n_time_steps = len(y.columns)\n",
    "n_inputs_pure = X.columns.tolist().index(\"EDSS_0\")+1\n",
    "\n",
    "pot = 1\n",
    "print(\"The RNN window will slide\", n_time_steps, \"times\")\n",
    "print(\"The input length of the training data will be\", pot, \"time slices, separated by 6 month intervals\")\n",
    "print(\"There will be\", n_inputs_pure, \"per time step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X reshaped is (355, 37, 110)\n",
      "y reshaped is (355, 37, 1)\n",
      "X reshaped is (153, 37, 110)\n",
      "y reshaped is (153, 37, 1)\n",
      "(355, 37, 110) (355, 37, 1) (153, 37, 110) (153, 37, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
    "\n",
    "# X train n_time_steps will be +1 to account for stretching\n",
    "# which will turn 11 time slices of 1 to 10 time slices of 2\n",
    "X_train_reshaped = X_train.values.reshape(-1, n_time_steps, n_inputs_pure) # extra time step for stretch\n",
    "y_train_reshaped = y_train.values.reshape(-1, n_time_steps, 1)\n",
    "print(\"X reshaped is \" + str(X_train_reshaped.shape))\n",
    "print(\"y reshaped is \" + str(y_train_reshaped.shape))\n",
    "\n",
    "X_test_reshaped = X_test.values.reshape(-1, n_time_steps, n_inputs_pure)\n",
    "y_test_reshaped = y_test.values.reshape(-1, n_time_steps, 1)\n",
    "print(\"X reshaped is \" + str(X_test_reshaped.shape))\n",
    "print(\"y reshaped is \" + str(y_test_reshaped.shape))\n",
    "\n",
    "y_train = y_train_reshaped.astype(float)\n",
    "y_test = y_test_reshaped.astype(float)\n",
    "X_train = X_train_reshaped.astype(float)\n",
    "X_test = X_test_reshaped.astype(float)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set values for the neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 inputs per time step ( 37 ) comprising 1 time slice, 110 features each\n"
     ]
    }
   ],
   "source": [
    "n_time_steps = n_time_steps\n",
    "\n",
    "pot = pot \n",
    "\n",
    "n_inputs = n_inputs_pure * pot\n",
    "\n",
    "n_units = 15\n",
    "\n",
    "n_output = 1\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "print(n_inputs, \"inputs per time step (\",n_time_steps,\") comprising\", pot, \"time slice,\", n_inputs_pure, \"features each\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 355 samples, validate on 153 samples\n",
      "Epoch 1/100\n",
      "355/355 [==============================] - 3s 8ms/step - loss: 4.2610 - val_loss: 4.8554\n",
      "Epoch 2/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 2.5702 - val_loss: 3.5479\n",
      "Epoch 3/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 1.6609 - val_loss: 2.3043\n",
      "Epoch 4/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.7109\n",
      "Epoch 5/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.7738 - val_loss: 1.4210\n",
      "Epoch 6/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.6264 - val_loss: 1.0919\n",
      "Epoch 7/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.5390 - val_loss: 0.9679\n",
      "Epoch 8/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.4903 - val_loss: 0.8690\n",
      "Epoch 9/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.4582 - val_loss: 0.8261\n",
      "Epoch 10/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.4322 - val_loss: 0.7830\n",
      "Epoch 11/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.4135 - val_loss: 0.7648\n",
      "Epoch 12/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.4010 - val_loss: 0.7306\n",
      "Epoch 13/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3873 - val_loss: 0.7152\n",
      "Epoch 14/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3780 - val_loss: 0.6881\n",
      "Epoch 15/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3728 - val_loss: 0.6700\n",
      "Epoch 16/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3628 - val_loss: 0.6457\n",
      "Epoch 17/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3541 - val_loss: 0.6198\n",
      "Epoch 18/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3451 - val_loss: 0.5884\n",
      "Epoch 19/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3361 - val_loss: 0.5714\n",
      "Epoch 20/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3312 - val_loss: 0.5575\n",
      "Epoch 21/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3252 - val_loss: 0.5387\n",
      "Epoch 22/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3165 - val_loss: 0.5140\n",
      "Epoch 23/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3121 - val_loss: 0.5058\n",
      "Epoch 24/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3065 - val_loss: 0.4925\n",
      "Epoch 25/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3031 - val_loss: 0.4819\n",
      "Epoch 26/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2994 - val_loss: 0.4770\n",
      "Epoch 27/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2955 - val_loss: 0.4751\n",
      "Epoch 28/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2914 - val_loss: 0.4546\n",
      "Epoch 29/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2885 - val_loss: 0.4528\n",
      "Epoch 30/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2914 - val_loss: 0.4434\n",
      "Epoch 31/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2804 - val_loss: 0.4440\n",
      "Epoch 32/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2790 - val_loss: 0.4261\n",
      "Epoch 33/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2744 - val_loss: 0.4219\n",
      "Epoch 34/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2720 - val_loss: 0.4133\n",
      "Epoch 35/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2694 - val_loss: 0.4103\n",
      "Epoch 36/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2662 - val_loss: 0.3938\n",
      "Epoch 37/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2590 - val_loss: 0.3864\n",
      "Epoch 38/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2604 - val_loss: 0.3823\n",
      "Epoch 39/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2543 - val_loss: 0.3779\n",
      "Epoch 40/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2536 - val_loss: 0.3761\n",
      "Epoch 41/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2507 - val_loss: 0.3762\n",
      "Epoch 42/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2485 - val_loss: 0.3683\n",
      "Epoch 43/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2486 - val_loss: 0.3699\n",
      "Epoch 44/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2447 - val_loss: 0.3626\n",
      "Epoch 45/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2435 - val_loss: 0.3621\n",
      "Epoch 46/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2416 - val_loss: 0.3665\n",
      "Epoch 47/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2407 - val_loss: 0.3596\n",
      "Epoch 48/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2392 - val_loss: 0.3575\n",
      "Epoch 49/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2376 - val_loss: 0.3531\n",
      "Epoch 50/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2348 - val_loss: 0.3503\n",
      "Epoch 51/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2338 - val_loss: 0.3502\n",
      "Epoch 52/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2312 - val_loss: 0.3529\n",
      "Epoch 53/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2303 - val_loss: 0.3469\n",
      "Epoch 54/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2282 - val_loss: 0.3470\n",
      "Epoch 55/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2270 - val_loss: 0.3436\n",
      "Epoch 56/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2264 - val_loss: 0.3538\n",
      "Epoch 57/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2267 - val_loss: 0.3418\n",
      "Epoch 58/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2230 - val_loss: 0.3442\n",
      "Epoch 59/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2239 - val_loss: 0.3414\n",
      "Epoch 60/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2215 - val_loss: 0.3390\n",
      "Epoch 61/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2194 - val_loss: 0.3367\n",
      "Epoch 62/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2186 - val_loss: 0.3374\n",
      "Epoch 63/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2157 - val_loss: 0.3361\n",
      "Epoch 64/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2145 - val_loss: 0.3398\n",
      "Epoch 65/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2133 - val_loss: 0.3348\n",
      "Epoch 66/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2114 - val_loss: 0.3366\n",
      "Epoch 67/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2126 - val_loss: 0.3355\n",
      "Epoch 68/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2109 - val_loss: 0.3398\n",
      "Epoch 69/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2114 - val_loss: 0.3369\n",
      "Epoch 70/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2118 - val_loss: 0.3423\n",
      "Epoch 71/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2069 - val_loss: 0.3327\n",
      "Epoch 72/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2047 - val_loss: 0.3392\n",
      "Epoch 73/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2042 - val_loss: 0.3371\n",
      "Epoch 74/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2024 - val_loss: 0.3457\n",
      "Epoch 75/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2043 - val_loss: 0.3493\n",
      "Epoch 76/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2066 - val_loss: 0.3531\n",
      "Epoch 77/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2030 - val_loss: 0.3473\n",
      "Epoch 78/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2026 - val_loss: 0.3501\n",
      "Epoch 79/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1993 - val_loss: 0.3641\n",
      "Epoch 80/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1990 - val_loss: 0.3440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2012 - val_loss: 0.3539\n",
      "Epoch 82/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1970 - val_loss: 0.3525\n",
      "Epoch 83/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1956 - val_loss: 0.3505\n",
      "Epoch 84/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.1948 - val_loss: 0.3431\n",
      "Epoch 85/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.1923 - val_loss: 0.3504\n",
      "Epoch 86/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1942 - val_loss: 0.3463\n",
      "Epoch 87/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1918 - val_loss: 0.3650\n",
      "Epoch 88/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1950 - val_loss: 0.3635\n",
      "Epoch 89/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1946 - val_loss: 0.3518\n",
      "Epoch 90/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1876 - val_loss: 0.3484\n",
      "Epoch 91/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1927 - val_loss: 0.3718\n",
      "Epoch 92/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1918 - val_loss: 0.3480\n",
      "Epoch 93/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1870 - val_loss: 0.3502\n",
      "Epoch 94/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1834 - val_loss: 0.3430\n",
      "Epoch 95/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1815 - val_loss: 0.3496\n",
      "Epoch 96/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1789 - val_loss: 0.3514\n",
      "Epoch 97/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1776 - val_loss: 0.3460\n",
      "Epoch 98/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1777 - val_loss: 0.3595\n",
      "Epoch 99/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1761 - val_loss: 0.3552\n",
      "Epoch 100/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.1742 - val_loss: 0.3512\n"
     ]
    }
   ],
   "source": [
    "model_adam = M.Sequential()\n",
    "\n",
    "# Each input data point has 20 timesteps, each with 26 features.\n",
    "# So the input shape (excluding batch_size) is (20, 26), which\n",
    "# matches the shape of each data point in data_x above.\n",
    "model_adam.add(L.LSTM(64, input_shape=(n_time_steps, n_inputs), return_sequences=True))\n",
    "model_adam.add(L.Dense(n_output, activation='linear'))\n",
    "\n",
    "# You need to pick appropriate loss/optimizers for your problem.\n",
    "# I'm just using these to make the example compile.\n",
    "model_adam.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "history_adam = model_adam.fit(X_train, y_train, batch_size = 32, \n",
    "                              epochs=100, validation_data=(X_test, y_test), \n",
    "                              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 355 samples, validate on 153 samples\n",
      "Epoch 1/100\n",
      "355/355 [==============================] - 3s 8ms/step - loss: 3.0965 - val_loss: 2.5707\n",
      "Epoch 2/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 1.5633 - val_loss: 1.4401\n",
      "Epoch 3/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.8056 - val_loss: 1.7039\n",
      "Epoch 4/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.8582 - val_loss: 1.0362\n",
      "Epoch 5/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.6086 - val_loss: 0.7450\n",
      "Epoch 6/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.4713 - val_loss: 0.9846\n",
      "Epoch 7/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.5447 - val_loss: 0.6799\n",
      "Epoch 8/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.4441 - val_loss: 0.6721\n",
      "Epoch 9/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.4505 - val_loss: 0.6351\n",
      "Epoch 10/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.4071 - val_loss: 0.6254\n",
      "Epoch 11/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3913 - val_loss: 0.5998\n",
      "Epoch 12/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3903 - val_loss: 0.5648\n",
      "Epoch 13/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3734 - val_loss: 0.5597\n",
      "Epoch 14/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3689 - val_loss: 0.6366\n",
      "Epoch 15/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3988 - val_loss: 0.5162\n",
      "Epoch 16/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3601 - val_loss: 0.5235\n",
      "Epoch 17/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3585 - val_loss: 0.7790\n",
      "Epoch 18/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3861 - val_loss: 0.5084\n",
      "Epoch 19/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3456 - val_loss: 0.4897\n",
      "Epoch 20/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3426 - val_loss: 0.4669\n",
      "Epoch 21/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3327 - val_loss: 0.4717\n",
      "Epoch 22/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3486 - val_loss: 0.4662\n",
      "Epoch 23/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3280 - val_loss: 0.4557\n",
      "Epoch 24/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3261 - val_loss: 0.4552\n",
      "Epoch 25/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3334 - val_loss: 0.4405\n",
      "Epoch 26/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3191 - val_loss: 0.4457\n",
      "Epoch 27/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3197 - val_loss: 0.4325\n",
      "Epoch 28/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3310 - val_loss: 0.4908\n",
      "Epoch 29/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3245 - val_loss: 0.4300\n",
      "Epoch 30/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3138 - val_loss: 0.4118\n",
      "Epoch 31/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3126 - val_loss: 0.4057\n",
      "Epoch 32/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3076 - val_loss: 0.4173\n",
      "Epoch 33/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3049 - val_loss: 0.3970\n",
      "Epoch 34/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3028 - val_loss: 0.4254\n",
      "Epoch 35/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3035 - val_loss: 0.3993\n",
      "Epoch 36/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3007 - val_loss: 0.4045\n",
      "Epoch 37/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.3028 - val_loss: 0.3893\n",
      "Epoch 38/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2966 - val_loss: 0.3873\n",
      "Epoch 39/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2956 - val_loss: 0.3844\n",
      "Epoch 40/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2954 - val_loss: 0.4144\n",
      "Epoch 41/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.3052 - val_loss: 0.3846\n",
      "Epoch 42/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2939 - val_loss: 0.3825\n",
      "Epoch 43/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2947 - val_loss: 0.4335\n",
      "Epoch 44/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2987 - val_loss: 0.3843\n",
      "Epoch 45/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2899 - val_loss: 0.3763\n",
      "Epoch 46/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2877 - val_loss: 0.4074\n",
      "Epoch 47/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2919 - val_loss: 0.3665\n",
      "Epoch 48/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2903 - val_loss: 0.4491\n",
      "Epoch 49/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2972 - val_loss: 0.3588\n",
      "Epoch 50/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2832 - val_loss: 0.3601\n",
      "Epoch 51/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2875 - val_loss: 0.3609\n",
      "Epoch 52/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2837 - val_loss: 0.3573\n",
      "Epoch 53/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2828 - val_loss: 0.3560\n",
      "Epoch 54/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2816 - val_loss: 0.3551\n",
      "Epoch 55/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2808 - val_loss: 0.3519\n",
      "Epoch 56/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2811 - val_loss: 0.3681\n",
      "Epoch 57/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2817 - val_loss: 0.3621\n",
      "Epoch 58/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2794 - val_loss: 0.3640\n",
      "Epoch 59/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2795 - val_loss: 0.3481\n",
      "Epoch 60/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2768 - val_loss: 0.3522\n",
      "Epoch 61/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2777 - val_loss: 0.3560\n",
      "Epoch 62/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2778 - val_loss: 0.3503\n",
      "Epoch 63/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2759 - val_loss: 0.3706\n",
      "Epoch 64/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2804 - val_loss: 0.3471\n",
      "Epoch 65/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2754 - val_loss: 0.3502\n",
      "Epoch 66/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2751 - val_loss: 0.3572\n",
      "Epoch 67/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2757 - val_loss: 0.3634\n",
      "Epoch 68/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2756 - val_loss: 0.3413\n",
      "Epoch 69/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2732 - val_loss: 0.3405\n",
      "Epoch 70/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2728 - val_loss: 0.3426\n",
      "Epoch 71/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2719 - val_loss: 0.3635\n",
      "Epoch 72/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2726 - val_loss: 0.3579\n",
      "Epoch 73/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2710 - val_loss: 0.3955\n",
      "Epoch 74/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2743 - val_loss: 0.3393\n",
      "Epoch 75/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2700 - val_loss: 0.3399\n",
      "Epoch 76/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2699 - val_loss: 0.3366\n",
      "Epoch 77/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2696 - val_loss: 0.3448\n",
      "Epoch 78/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2708 - val_loss: 0.3567\n",
      "Epoch 79/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2693 - val_loss: 0.3345\n",
      "Epoch 80/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2683 - val_loss: 0.3356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2695 - val_loss: 0.3334\n",
      "Epoch 82/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2684 - val_loss: 0.3368\n",
      "Epoch 83/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2666 - val_loss: 0.3321\n",
      "Epoch 84/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2669 - val_loss: 0.3825\n",
      "Epoch 85/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2723 - val_loss: 0.3329\n",
      "Epoch 86/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2668 - val_loss: 0.3345\n",
      "Epoch 87/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2666 - val_loss: 0.3306\n",
      "Epoch 88/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2650 - val_loss: 0.3296\n",
      "Epoch 89/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2648 - val_loss: 0.3312\n",
      "Epoch 90/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2641 - val_loss: 0.3289\n",
      "Epoch 91/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2656 - val_loss: 0.3491\n",
      "Epoch 92/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2692 - val_loss: 0.3283\n",
      "Epoch 93/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2639 - val_loss: 0.3281\n",
      "Epoch 94/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2640 - val_loss: 0.3302\n",
      "Epoch 95/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2632 - val_loss: 0.3691\n",
      "Epoch 96/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2662 - val_loss: 0.3520\n",
      "Epoch 97/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2665 - val_loss: 0.3299\n",
      "Epoch 98/100\n",
      "355/355 [==============================] - 1s 3ms/step - loss: 0.2625 - val_loss: 0.3265\n",
      "Epoch 99/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2623 - val_loss: 0.3583\n",
      "Epoch 100/100\n",
      "355/355 [==============================] - 1s 4ms/step - loss: 0.2676 - val_loss: 0.3252\n"
     ]
    }
   ],
   "source": [
    "model_sgd = M.Sequential()\n",
    "\n",
    "\n",
    "model_sgd.add(L.LSTM(64, input_shape=(n_time_steps, n_inputs), return_sequences=True))\n",
    "model_sgd.add(L.Dense(n_output, activation='linear'))\n",
    "\n",
    "model_sgd.compile(optimizer = 'sgd', loss = 'mean_squared_error')\n",
    "\n",
    "history_sgd = model_sgd.fit(X_train, y_train, batch_size = 32, \n",
    "                              epochs=100, validation_data=(X_test, y_test), \n",
    "                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_test_sgd = history_sgd.__dict__['history']['val_loss']\n",
    "mse_train_sgd = history_sgd.__dict__['history']['loss']\n",
    "sgd_params = history_sgd.__dict__['params']\n",
    "\n",
    "mse_test_adam = history_adam.__dict__['history']['val_loss']\n",
    "mse_train_adam = history_adam.__dict__['history']['loss']\n",
    "adam_params = history_adam.__dict__['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Train Scores\n",
      "SGD 0.2622849494638577\n",
      "SGD epoch: 98\n",
      "Adam 0.1741528462356245\n",
      "Adam epoch: 99\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mse_train_adam)\n",
    "plt.plot(mse_train_sgd)\n",
    "\n",
    "plt.legend(['train_adam','train_sgd'])\n",
    "\n",
    "print(\"Best Train Scores\")\n",
    "print(\"SGD\", np.min(mse_train_sgd))\n",
    "print(\"SGD epoch:\",np.argmin(mse_train_sgd))\n",
    "\n",
    "print(\"Adam\", np.min(mse_train_adam))\n",
    "print(\"Adam epoch:\",np.argmin(mse_train_adam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Test Scores\n",
      "SGD 0.3252020996380476\n",
      "SGD epoch: 99\n",
      "Adam 0.33265872484718273\n",
      "Adam epoch: 70\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mse_test_adam)\n",
    "plt.plot(mse_test_sgd)\n",
    "\n",
    "plt.legend(['test_adam','test_sgd'])\n",
    "\n",
    "print(\"Best Test Scores\")\n",
    "print(\"SGD\", np.min(mse_test_sgd))\n",
    "print(\"SGD epoch:\",np.argmin(mse_test_sgd))\n",
    "\n",
    "print(\"Adam\", np.min(mse_test_adam))\n",
    "print(\"Adam epoch:\",np.argmin(mse_test_adam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
